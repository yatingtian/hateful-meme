{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7406562-3a24-4d22-8c01-fd26ec207769",
   "metadata": {},
   "source": [
    "# Hateful Meme Baseline Reproduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a999f4c-93df-4b25-8718-91468cfbd89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process is terminated.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/facebookresearch/mmf.git\n",
    "!cd mmf\n",
    "!pip install --editable . --user --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1cf295-3525-474f-88ca-5075ab79878d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mmf 1.0.0rc12 requires torch<=1.9.0,>=1.6.0, but you have torch 1.10.0 which is incompatible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1df5a8c0-37d6-44ea-854a-bc969a985dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38d4ab15-dec3-4b66-a40c-4fcfa65ddfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mmf_convert_hm --zip_file \"hm_data1.zip\" --password 1 --bypass_checksum 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29203690-857b-4cd9-8566-56c9cd57006c",
   "metadata": {},
   "source": [
    "mmf_run config='projects/hateful_memes/configs/visual_bert/from_coco.yaml' model=visual_bert dataset=hateful_memes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bb96a9-6477-4281-97e9-8f4f71f89514",
   "metadata": {},
   "source": [
    "mmf_run config='projects/hateful_memes/configs/visual_bert/from_coco.yaml' model=visual_bert dataset=hateful_memes run_type=train_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7124bef2-aaa6-4e96-99fe-71527c279bfa",
   "metadata": {},
   "source": [
    "mmf_run config=projects/hateful_memes/configs/visual_bert/from_coco.yaml model=visual_bert dataset=hateful_memes run_type=train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04018dee-156e-4c18-a95b-b396da24388e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.7/site-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_USER_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
      "  category=UserWarning,\n",
      "/home/jupyter/.local/lib/python3.7/site-packages/omegaconf/resolvers/__init__.py:13: UserWarning: The `env` resolver is deprecated, see https://github.com/omry/omegaconf/issues/573\n",
      "  \"The `env` resolver is deprecated, see https://github.com/omry/omegaconf/issues/573\"\n",
      "\u001b[32m2021-11-30T13:53:27 | mmf.utils.configuration: \u001b[0mOverriding option config to projects/hateful_memes/configs/visual_bert/from_coco.yaml\n",
      "\u001b[32m2021-11-30T13:53:27 | mmf.utils.configuration: \u001b[0mOverriding option model to visual_bert\n",
      "\u001b[32m2021-11-30T13:53:27 | mmf.utils.configuration: \u001b[0mOverriding option datasets to hateful_memes\n",
      "\u001b[32m2021-11-30T13:53:27 | mmf.utils.configuration: \u001b[0mOverriding option training.log_interval to 50\n",
      "\u001b[32m2021-11-30T13:53:27 | mmf.utils.configuration: \u001b[0mOverriding option training.max_updates to 3000\n",
      "\u001b[32m2021-11-30T13:53:27 | mmf.utils.configuration: \u001b[0mOverriding option training.batch_size to 16\n",
      "\u001b[32m2021-11-30T13:53:27 | mmf.utils.configuration: \u001b[0mOverriding option training.evaluation_interval to 500\n",
      "/home/jupyter/.local/lib/python3.7/site-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_LOG_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
      "  category=UserWarning,\n",
      "/home/jupyter/.local/lib/python3.7/site-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_REPORT_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
      "  category=UserWarning,\n",
      "/home/jupyter/.local/lib/python3.7/site-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_TENSORBOARD_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
      "  category=UserWarning,\n",
      "/home/jupyter/.local/lib/python3.7/site-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_WANDB_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
      "  category=UserWarning,\n",
      "\u001b[32m2021-11-30T13:53:27 | mmf: \u001b[0mLogging to: ./save/train.log\n",
      "\u001b[32m2021-11-30T13:53:27 | mmf_cli.run: \u001b[0mNamespace(config_override=None, local_rank=None, opts=['config=projects/hateful_memes/configs/visual_bert/from_coco.yaml', 'model=visual_bert', 'dataset=hateful_memes', 'training.log_interval=50', 'training.max_updates=3000', 'training.batch_size=16', 'training.evaluation_interval=500'])\n",
      "\u001b[32m2021-11-30T13:53:27 | mmf_cli.run: \u001b[0mTorch version: 1.9.0+cu102\n",
      "\u001b[32m2021-11-30T13:53:27 | mmf.utils.general: \u001b[0mCUDA Device 0 is: Tesla K80\n",
      "\u001b[32m2021-11-30T13:53:27 | mmf_cli.run: \u001b[0mUsing seed 27100065\n",
      "\u001b[32m2021-11-30T13:53:27 | mmf.trainers.mmf_trainer: \u001b[0mLoading datasets\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/jupyter/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.10.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/jupyter/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/jupyter/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/jupyter/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/jupyter/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.10.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "\u001b[32m2021-11-30T13:53:29 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
      "\u001b[32m2021-11-30T13:53:29 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
      "\u001b[32m2021-11-30T13:53:29 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
      "\u001b[32m2021-11-30T13:53:29 | mmf.trainers.mmf_trainer: \u001b[0mLoading model\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bert_model_name\": \"bert-base-uncased\",\n",
      "  \"bypass_transformer\": false,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_strategy\": \"plain\",\n",
      "  \"finetune_lr_multiplier\": 1,\n",
      "  \"freeze_base\": false,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"losses\": [\n",
      "    \"cross_entropy\"\n",
      "  ],\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model\": \"visual_bert\",\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_strategy\": \"default\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"random_initialize\": false,\n",
      "  \"special_visual_initialize\": true,\n",
      "  \"training_head_type\": \"classification\",\n",
      "  \"transformers_version\": \"4.10.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"visual_embedding_dim\": 2048,\n",
      "  \"vocab_size\": 30522,\n",
      "  \"zerobias\": false\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/jupyter/.cache/torch/mmf/distributed_-1/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing VisualBERTBase: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing VisualBERTBase from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisualBERTBase from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of VisualBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.embeddings.projection.bias', 'bert.embeddings.projection.weight', 'bert.embeddings.token_type_embeddings_visual.weight', 'bert.embeddings.position_embeddings_visual.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2021-11-30T13:53:34 | mmf.trainers.mmf_trainer: \u001b[0mLoading optimizer\n",
      "\u001b[32m2021-11-30T13:53:34 | mmf.trainers.mmf_trainer: \u001b[0mLoading metrics\n",
      "\u001b[32m2021-11-30T13:53:34 | mmf.utils.checkpoint: \u001b[0mLoading checkpoint\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-11-30T13:53:35 | mmf: \u001b[0mKey data_parallel is not present in registry, returning default value of None\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-11-30T13:53:35 | mmf: \u001b[0mKey distributed is not present in registry, returning default value of None\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-11-30T13:53:35 | mmf: \u001b[0mKey data_parallel is not present in registry, returning default value of None\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-11-30T13:53:35 | mmf: \u001b[0mKey distributed is not present in registry, returning default value of None\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.word_embeddings.weight from model.bert.embeddings.word_embeddings.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.position_embeddings.weight from model.bert.embeddings.position_embeddings.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.token_type_embeddings.weight from model.bert.embeddings.token_type_embeddings.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.LayerNorm.weight from model.bert.embeddings.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.LayerNorm.bias from model.bert.embeddings.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.token_type_embeddings_visual.weight from model.bert.embeddings.token_type_embeddings_visual.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.position_embeddings_visual.weight from model.bert.embeddings.position_embeddings_visual.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.projection.weight from model.bert.embeddings.projection.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.projection.bias from model.bert.embeddings.projection.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.query.weight from model.bert.encoder.layer.0.attention.self.query.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.query.bias from model.bert.encoder.layer.0.attention.self.query.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.key.weight from model.bert.encoder.layer.0.attention.self.key.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.key.bias from model.bert.encoder.layer.0.attention.self.key.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.value.weight from model.bert.encoder.layer.0.attention.self.value.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.value.bias from model.bert.encoder.layer.0.attention.self.value.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.output.dense.weight from model.bert.encoder.layer.0.attention.output.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.output.dense.bias from model.bert.encoder.layer.0.attention.output.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.output.LayerNorm.weight from model.bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.output.LayerNorm.bias from model.bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.intermediate.dense.weight from model.bert.encoder.layer.0.intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.intermediate.dense.bias from model.bert.encoder.layer.0.intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.output.dense.weight from model.bert.encoder.layer.0.output.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.output.dense.bias from model.bert.encoder.layer.0.output.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.output.LayerNorm.weight from model.bert.encoder.layer.0.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.output.LayerNorm.bias from model.bert.encoder.layer.0.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.query.weight from model.bert.encoder.layer.1.attention.self.query.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.query.bias from model.bert.encoder.layer.1.attention.self.query.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.key.weight from model.bert.encoder.layer.1.attention.self.key.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.key.bias from model.bert.encoder.layer.1.attention.self.key.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.value.weight from model.bert.encoder.layer.1.attention.self.value.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.value.bias from model.bert.encoder.layer.1.attention.self.value.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.output.dense.weight from model.bert.encoder.layer.1.attention.output.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.output.dense.bias from model.bert.encoder.layer.1.attention.output.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.output.LayerNorm.weight from model.bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.output.LayerNorm.bias from model.bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.intermediate.dense.weight from model.bert.encoder.layer.1.intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.intermediate.dense.bias from model.bert.encoder.layer.1.intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.output.dense.weight from model.bert.encoder.layer.1.output.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.output.dense.bias from model.bert.encoder.layer.1.output.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.output.LayerNorm.weight from model.bert.encoder.layer.1.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.output.LayerNorm.bias from model.bert.encoder.layer.1.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.query.weight from model.bert.encoder.layer.2.attention.self.query.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.query.bias from model.bert.encoder.layer.2.attention.self.query.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.key.weight from model.bert.encoder.layer.2.attention.self.key.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.key.bias from model.bert.encoder.layer.2.attention.self.key.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.value.weight from model.bert.encoder.layer.2.attention.self.value.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.value.bias from model.bert.encoder.layer.2.attention.self.value.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.output.dense.weight from model.bert.encoder.layer.2.attention.output.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.output.dense.bias from model.bert.encoder.layer.2.attention.output.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.output.LayerNorm.weight from model.bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.output.LayerNorm.bias from model.bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.intermediate.dense.weight from model.bert.encoder.layer.2.intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.intermediate.dense.bias from model.bert.encoder.layer.2.intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.output.dense.weight from model.bert.encoder.layer.2.output.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.output.dense.bias from model.bert.encoder.layer.2.output.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.output.LayerNorm.weight from model.bert.encoder.layer.2.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.output.LayerNorm.bias from model.bert.encoder.layer.2.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.query.weight from model.bert.encoder.layer.3.attention.self.query.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.query.bias from model.bert.encoder.layer.3.attention.self.query.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.key.weight from model.bert.encoder.layer.3.attention.self.key.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.key.bias from model.bert.encoder.layer.3.attention.self.key.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.value.weight from model.bert.encoder.layer.3.attention.self.value.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.value.bias from model.bert.encoder.layer.3.attention.self.value.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.output.dense.weight from model.bert.encoder.layer.3.attention.output.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.output.dense.bias from model.bert.encoder.layer.3.attention.output.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.output.LayerNorm.weight from model.bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.output.LayerNorm.bias from model.bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.intermediate.dense.weight from model.bert.encoder.layer.3.intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.intermediate.dense.bias from model.bert.encoder.layer.3.intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.output.dense.weight from model.bert.encoder.layer.3.output.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.output.dense.bias from model.bert.encoder.layer.3.output.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.output.LayerNorm.weight from model.bert.encoder.layer.3.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.output.LayerNorm.bias from model.bert.encoder.layer.3.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.query.weight from model.bert.encoder.layer.4.attention.self.query.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.query.bias from model.bert.encoder.layer.4.attention.self.query.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.key.weight from model.bert.encoder.layer.4.attention.self.key.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.key.bias from model.bert.encoder.layer.4.attention.self.key.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.value.weight from model.bert.encoder.layer.4.attention.self.value.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.value.bias from model.bert.encoder.layer.4.attention.self.value.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.output.dense.weight from model.bert.encoder.layer.4.attention.output.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.output.dense.bias from model.bert.encoder.layer.4.attention.output.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.output.LayerNorm.weight from model.bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.output.LayerNorm.bias from model.bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.intermediate.dense.weight from model.bert.encoder.layer.4.intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.intermediate.dense.bias from model.bert.encoder.layer.4.intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.output.dense.weight from model.bert.encoder.layer.4.output.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.output.dense.bias from model.bert.encoder.layer.4.output.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.output.LayerNorm.weight from model.bert.encoder.layer.4.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.output.LayerNorm.bias from model.bert.encoder.layer.4.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.query.weight from model.bert.encoder.layer.5.attention.self.query.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.query.bias from model.bert.encoder.layer.5.attention.self.query.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.key.weight from model.bert.encoder.layer.5.attention.self.key.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.key.bias from model.bert.encoder.layer.5.attention.self.key.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.value.weight from model.bert.encoder.layer.5.attention.self.value.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.value.bias from model.bert.encoder.layer.5.attention.self.value.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.output.dense.weight from model.bert.encoder.layer.5.attention.output.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.output.dense.bias from model.bert.encoder.layer.5.attention.output.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.output.LayerNorm.weight from model.bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.output.LayerNorm.bias from model.bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.intermediate.dense.weight from model.bert.encoder.layer.5.intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.intermediate.dense.bias from model.bert.encoder.layer.5.intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.output.dense.weight from model.bert.encoder.layer.5.output.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.output.dense.bias from model.bert.encoder.layer.5.output.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.output.LayerNorm.weight from model.bert.encoder.layer.5.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.output.LayerNorm.bias from model.bert.encoder.layer.5.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.query.weight from model.bert.encoder.layer.6.attention.self.query.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.query.bias from model.bert.encoder.layer.6.attention.self.query.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.key.weight from model.bert.encoder.layer.6.attention.self.key.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.key.bias from model.bert.encoder.layer.6.attention.self.key.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.value.weight from model.bert.encoder.layer.6.attention.self.value.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.value.bias from model.bert.encoder.layer.6.attention.self.value.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.output.dense.weight from model.bert.encoder.layer.6.attention.output.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.output.dense.bias from model.bert.encoder.layer.6.attention.output.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.output.LayerNorm.weight from model.bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.output.LayerNorm.bias from model.bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.intermediate.dense.weight from model.bert.encoder.layer.6.intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.intermediate.dense.bias from model.bert.encoder.layer.6.intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.output.dense.weight from model.bert.encoder.layer.6.output.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.output.dense.bias from model.bert.encoder.layer.6.output.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.output.LayerNorm.weight from model.bert.encoder.layer.6.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.output.LayerNorm.bias from model.bert.encoder.layer.6.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.query.weight from model.bert.encoder.layer.7.attention.self.query.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.query.bias from model.bert.encoder.layer.7.attention.self.query.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.key.weight from model.bert.encoder.layer.7.attention.self.key.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.key.bias from model.bert.encoder.layer.7.attention.self.key.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.value.weight from model.bert.encoder.layer.7.attention.self.value.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.value.bias from model.bert.encoder.layer.7.attention.self.value.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.output.dense.weight from model.bert.encoder.layer.7.attention.output.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.output.dense.bias from model.bert.encoder.layer.7.attention.output.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.output.LayerNorm.weight from model.bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.output.LayerNorm.bias from model.bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.intermediate.dense.weight from model.bert.encoder.layer.7.intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.intermediate.dense.bias from model.bert.encoder.layer.7.intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.output.dense.weight from model.bert.encoder.layer.7.output.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.output.dense.bias from model.bert.encoder.layer.7.output.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.output.LayerNorm.weight from model.bert.encoder.layer.7.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.output.LayerNorm.bias from model.bert.encoder.layer.7.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.query.weight from model.bert.encoder.layer.8.attention.self.query.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.query.bias from model.bert.encoder.layer.8.attention.self.query.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.key.weight from model.bert.encoder.layer.8.attention.self.key.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.key.bias from model.bert.encoder.layer.8.attention.self.key.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.value.weight from model.bert.encoder.layer.8.attention.self.value.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.value.bias from model.bert.encoder.layer.8.attention.self.value.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.output.dense.weight from model.bert.encoder.layer.8.attention.output.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.output.dense.bias from model.bert.encoder.layer.8.attention.output.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.output.LayerNorm.weight from model.bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.output.LayerNorm.bias from model.bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.intermediate.dense.weight from model.bert.encoder.layer.8.intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.intermediate.dense.bias from model.bert.encoder.layer.8.intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.output.dense.weight from model.bert.encoder.layer.8.output.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.output.dense.bias from model.bert.encoder.layer.8.output.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.output.LayerNorm.weight from model.bert.encoder.layer.8.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.output.LayerNorm.bias from model.bert.encoder.layer.8.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.query.weight from model.bert.encoder.layer.9.attention.self.query.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.query.bias from model.bert.encoder.layer.9.attention.self.query.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.key.weight from model.bert.encoder.layer.9.attention.self.key.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.key.bias from model.bert.encoder.layer.9.attention.self.key.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.value.weight from model.bert.encoder.layer.9.attention.self.value.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.value.bias from model.bert.encoder.layer.9.attention.self.value.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.output.dense.weight from model.bert.encoder.layer.9.attention.output.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.output.dense.bias from model.bert.encoder.layer.9.attention.output.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.output.LayerNorm.weight from model.bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.output.LayerNorm.bias from model.bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.intermediate.dense.weight from model.bert.encoder.layer.9.intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.intermediate.dense.bias from model.bert.encoder.layer.9.intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.output.dense.weight from model.bert.encoder.layer.9.output.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.output.dense.bias from model.bert.encoder.layer.9.output.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.output.LayerNorm.weight from model.bert.encoder.layer.9.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.output.LayerNorm.bias from model.bert.encoder.layer.9.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.query.weight from model.bert.encoder.layer.10.attention.self.query.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.query.bias from model.bert.encoder.layer.10.attention.self.query.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.key.weight from model.bert.encoder.layer.10.attention.self.key.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.key.bias from model.bert.encoder.layer.10.attention.self.key.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.value.weight from model.bert.encoder.layer.10.attention.self.value.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.value.bias from model.bert.encoder.layer.10.attention.self.value.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.output.dense.weight from model.bert.encoder.layer.10.attention.output.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.output.dense.bias from model.bert.encoder.layer.10.attention.output.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.output.LayerNorm.weight from model.bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.output.LayerNorm.bias from model.bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.intermediate.dense.weight from model.bert.encoder.layer.10.intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.intermediate.dense.bias from model.bert.encoder.layer.10.intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.output.dense.weight from model.bert.encoder.layer.10.output.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.output.dense.bias from model.bert.encoder.layer.10.output.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.output.LayerNorm.weight from model.bert.encoder.layer.10.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.output.LayerNorm.bias from model.bert.encoder.layer.10.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.query.weight from model.bert.encoder.layer.11.attention.self.query.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.query.bias from model.bert.encoder.layer.11.attention.self.query.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.key.weight from model.bert.encoder.layer.11.attention.self.key.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.key.bias from model.bert.encoder.layer.11.attention.self.key.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.value.weight from model.bert.encoder.layer.11.attention.self.value.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.value.bias from model.bert.encoder.layer.11.attention.self.value.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.output.dense.weight from model.bert.encoder.layer.11.attention.output.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.output.dense.bias from model.bert.encoder.layer.11.attention.output.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.output.LayerNorm.weight from model.bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.output.LayerNorm.bias from model.bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.intermediate.dense.weight from model.bert.encoder.layer.11.intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.intermediate.dense.bias from model.bert.encoder.layer.11.intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.output.dense.weight from model.bert.encoder.layer.11.output.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.output.dense.bias from model.bert.encoder.layer.11.output.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.output.LayerNorm.weight from model.bert.encoder.layer.11.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.output.LayerNorm.bias from model.bert.encoder.layer.11.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.pooler.dense.weight from model.bert.pooler.dense.weight\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.pooler.dense.bias from model.bert.pooler.dense.bias\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mPretrained model loaded\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCheckpoint loaded.\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCurrent num updates: 0\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCurrent iteration: 0\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.checkpoint: \u001b[0mCurrent epoch: 0\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.trainers.mmf_trainer: \u001b[0m===== Model =====\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.trainers.mmf_trainer: \u001b[0mVisualBERT(\n",
      "  (model): VisualBERTForClassification(\n",
      "    (bert): VisualBERTBase(\n",
      "      (embeddings): BertVisioLinguisticEmbeddings(\n",
      "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (token_type_embeddings_visual): Embedding(2, 768)\n",
      "        (position_embeddings_visual): Embedding(512, 768)\n",
      "        (projection): Linear(in_features=2048, out_features=768, bias=True)\n",
      "      )\n",
      "      (encoder): BertEncoderJit(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayerJit(\n",
      "            (attention): BertAttentionJit(\n",
      "              (self): BertSelfAttentionJit(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayerJit(\n",
      "            (attention): BertAttentionJit(\n",
      "              (self): BertSelfAttentionJit(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayerJit(\n",
      "            (attention): BertAttentionJit(\n",
      "              (self): BertSelfAttentionJit(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayerJit(\n",
      "            (attention): BertAttentionJit(\n",
      "              (self): BertSelfAttentionJit(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayerJit(\n",
      "            (attention): BertAttentionJit(\n",
      "              (self): BertSelfAttentionJit(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayerJit(\n",
      "            (attention): BertAttentionJit(\n",
      "              (self): BertSelfAttentionJit(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayerJit(\n",
      "            (attention): BertAttentionJit(\n",
      "              (self): BertSelfAttentionJit(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayerJit(\n",
      "            (attention): BertAttentionJit(\n",
      "              (self): BertSelfAttentionJit(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayerJit(\n",
      "            (attention): BertAttentionJit(\n",
      "              (self): BertSelfAttentionJit(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayerJit(\n",
      "            (attention): BertAttentionJit(\n",
      "              (self): BertSelfAttentionJit(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayerJit(\n",
      "            (attention): BertAttentionJit(\n",
      "              (self): BertSelfAttentionJit(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayerJit(\n",
      "            (attention): BertAttentionJit(\n",
      "              (self): BertSelfAttentionJit(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (classifier): Sequential(\n",
      "      (0): BertPredictionHeadTransform(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      )\n",
      "      (1): Linear(in_features=768, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (losses): Losses(\n",
      "    (losses): ModuleList(\n",
      "      (0): MMFLoss(\n",
      "        (loss_criterion): CrossEntropyLoss(\n",
      "          (loss_fn): CrossEntropyLoss()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.utils.general: \u001b[0mTotal Parameters: 112044290. Trained Parameters: 112044290\n",
      "\u001b[32m2021-11-30T13:53:35 | mmf.trainers.core.training_loop: \u001b[0mStarting training...\n",
      "\u001b[32m2021-11-30T13:54:40 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 50/3000, train/hateful_memes/cross_entropy: 0.6373, train/hateful_memes/cross_entropy/avg: 0.6373, train/total_loss: 0.6373, train/total_loss/avg: 0.6373, max mem: 5480.0, experiment: run, epoch: 1, num_updates: 50, iterations: 50, max_updates: 3000, lr: 0., ups: 0.77, time: 01m 05s 038ms, time_since_start: 01m 05s 601ms, eta: 01h 08m 18s 219ms\n",
      "\u001b[32m2021-11-30T13:55:42 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 100/3000, train/hateful_memes/cross_entropy: 0.6373, train/hateful_memes/cross_entropy/avg: 0.6385, train/total_loss: 0.6373, train/total_loss/avg: 0.6385, max mem: 5480.0, experiment: run, epoch: 1, num_updates: 100, iterations: 100, max_updates: 3000, lr: 0., ups: 0.81, time: 01m 02s 648ms, time_since_start: 02m 08s 249ms, eta: 01h 04m 40s 696ms\n",
      "\u001b[32m2021-11-30T13:56:45 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 150/3000, train/hateful_memes/cross_entropy: 0.6397, train/hateful_memes/cross_entropy/avg: 0.6424, train/total_loss: 0.6397, train/total_loss/avg: 0.6424, max mem: 5480.0, experiment: run, epoch: 1, num_updates: 150, iterations: 150, max_updates: 3000, lr: 0., ups: 0.81, time: 01m 02s 589ms, time_since_start: 03m 10s 839ms, eta: 01h 03m 30s 226ms\n",
      "\u001b[32m2021-11-30T13:57:48 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 200/3000, train/hateful_memes/cross_entropy: 0.6373, train/hateful_memes/cross_entropy/avg: 0.6236, train/total_loss: 0.6373, train/total_loss/avg: 0.6236, max mem: 5480.0, experiment: run, epoch: 1, num_updates: 200, iterations: 200, max_updates: 3000, lr: 0.00001, ups: 0.81, time: 01m 02s 599ms, time_since_start: 04m 13s 439ms, eta: 01h 02m 23s 970ms\n",
      "\u001b[32m2021-11-30T13:58:50 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 250/3000, train/hateful_memes/cross_entropy: 0.6373, train/hateful_memes/cross_entropy/avg: 0.6194, train/total_loss: 0.6373, train/total_loss/avg: 0.6194, max mem: 5480.0, experiment: run, epoch: 1, num_updates: 250, iterations: 250, max_updates: 3000, lr: 0.00001, ups: 0.81, time: 01m 02s 716ms, time_since_start: 05m 16s 155ms, eta: 01h 01m 23s 943ms\n",
      "\u001b[32m2021-11-30T13:59:53 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 300/3000, train/hateful_memes/cross_entropy: 0.6373, train/hateful_memes/cross_entropy/avg: 0.6314, train/total_loss: 0.6373, train/total_loss/avg: 0.6314, max mem: 5480.0, experiment: run, epoch: 1, num_updates: 300, iterations: 300, max_updates: 3000, lr: 0.00001, ups: 0.81, time: 01m 02s 616ms, time_since_start: 06m 18s 771ms, eta: 01h 11s 209ms\n",
      "\u001b[32m2021-11-30T14:00:56 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 350/3000, train/hateful_memes/cross_entropy: 0.6397, train/hateful_memes/cross_entropy/avg: 0.6329, train/total_loss: 0.6397, train/total_loss/avg: 0.6329, max mem: 5480.0, experiment: run, epoch: 1, num_updates: 350, iterations: 350, max_updates: 3000, lr: 0.00001, ups: 0.81, time: 01m 02s 593ms, time_since_start: 07m 21s 365ms, eta: 59m 03s 040ms\n",
      "\u001b[32m2021-11-30T14:01:58 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 400/3000, train/hateful_memes/cross_entropy: 0.6397, train/hateful_memes/cross_entropy/avg: 0.6408, train/total_loss: 0.6397, train/total_loss/avg: 0.6408, max mem: 5480.0, experiment: run, epoch: 1, num_updates: 400, iterations: 400, max_updates: 3000, lr: 0.00001, ups: 0.81, time: 01m 02s 662ms, time_since_start: 08m 24s 027ms, eta: 58m 015ms\n",
      "\u001b[32m2021-11-30T14:03:01 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 450/3000, train/hateful_memes/cross_entropy: 0.6397, train/hateful_memes/cross_entropy/avg: 0.6293, train/total_loss: 0.6397, train/total_loss/avg: 0.6293, max mem: 5480.0, experiment: run, epoch: 1, num_updates: 450, iterations: 450, max_updates: 3000, lr: 0.00001, ups: 0.81, time: 01m 02s 700ms, time_since_start: 09m 26s 728ms, eta: 56m 55s 166ms\n",
      "\u001b[32m2021-11-30T14:04:04 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 500/3000, train/hateful_memes/cross_entropy: 0.6373, train/hateful_memes/cross_entropy/avg: 0.6070, train/total_loss: 0.6373, train/total_loss/avg: 0.6070, max mem: 5480.0, experiment: run, epoch: 1, num_updates: 500, iterations: 500, max_updates: 3000, lr: 0.00001, ups: 0.81, time: 01m 02s 591ms, time_since_start: 10m 29s 320ms, eta: 55m 42s 407ms\n",
      "\u001b[32m2021-11-30T14:04:04 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
      "\u001b[32m2021-11-30T14:04:04 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
      "\u001b[32m2021-11-30T14:04:33 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished training. Loaded 34\n",
      "\u001b[32m2021-11-30T14:04:33 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
      "\u001b[32m2021-11-30T14:04:33 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
      "\u001b[32m2021-11-30T14:04:36 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
      "\u001b[32m2021-11-30T14:04:38 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
      "\u001b[32m2021-11-30T14:04:40 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
      "\u001b[32m2021-11-30T14:04:40 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 500/3000, val/hateful_memes/cross_entropy: 0.7247, val/total_loss: 0.7247, val/hateful_memes/accuracy: 0.6278, val/hateful_memes/binary_f1: 0.2898, val/hateful_memes/roc_auc: 0.6192, num_updates: 500, epoch: 1, iterations: 500, max_updates: 3000, val_time: 36s 352ms, best_update: 500, best_iteration: 500, best_val/hateful_memes/roc_auc: 0.619206\n",
      "\u001b[32m2021-11-30T14:06:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 550/3000, train/hateful_memes/cross_entropy: 0.6373, train/hateful_memes/cross_entropy/avg: 0.5772, train/total_loss: 0.6373, train/total_loss/avg: 0.5772, max mem: 5497.0, experiment: run, epoch: 2, num_updates: 550, iterations: 550, max_updates: 3000, lr: 0.00001, ups: 0.54, time: 01m 33s 335ms, time_since_start: 12m 39s 022ms, eta: 01h 21m 24s 419ms\n",
      "\u001b[32m2021-11-30T14:07:16 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 600/3000, train/hateful_memes/cross_entropy: 0.6024, train/hateful_memes/cross_entropy/avg: 0.5647, train/total_loss: 0.6024, train/total_loss/avg: 0.5647, max mem: 5497.0, experiment: run, epoch: 2, num_updates: 600, iterations: 600, max_updates: 3000, lr: 0.00002, ups: 0.79, time: 01m 03s 052ms, time_since_start: 13m 42s 074ms, eta: 53m 52s 318ms\n",
      "\u001b[32m2021-11-30T14:08:19 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 650/3000, train/hateful_memes/cross_entropy: 0.6373, train/hateful_memes/cross_entropy/avg: 0.5782, train/total_loss: 0.6373, train/total_loss/avg: 0.5782, max mem: 5497.0, experiment: run, epoch: 2, num_updates: 650, iterations: 650, max_updates: 3000, lr: 0.00002, ups: 0.79, time: 01m 03s 079ms, time_since_start: 14m 45s 154ms, eta: 52m 46s 341ms\n",
      "\u001b[32m2021-11-30T14:09:22 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 700/3000, train/hateful_memes/cross_entropy: 0.6024, train/hateful_memes/cross_entropy/avg: 0.5693, train/total_loss: 0.6024, train/total_loss/avg: 0.5693, max mem: 5497.0, experiment: run, epoch: 2, num_updates: 700, iterations: 700, max_updates: 3000, lr: 0.00002, ups: 0.81, time: 01m 02s 938ms, time_since_start: 15m 48s 092ms, eta: 51m 32s 033ms\n",
      "\u001b[32m2021-11-30T14:10:25 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 750/3000, train/hateful_memes/cross_entropy: 0.6024, train/hateful_memes/cross_entropy/avg: 0.5666, train/total_loss: 0.6024, train/total_loss/avg: 0.5666, max mem: 5497.0, experiment: run, epoch: 2, num_updates: 750, iterations: 750, max_updates: 3000, lr: 0.00002, ups: 0.81, time: 01m 02s 999ms, time_since_start: 16m 51s 092ms, eta: 50m 27s 779ms\n",
      "\u001b[32m2021-11-30T14:11:28 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 800/3000, train/hateful_memes/cross_entropy: 0.5673, train/hateful_memes/cross_entropy/avg: 0.5659, train/total_loss: 0.5673, train/total_loss/avg: 0.5659, max mem: 5497.0, experiment: run, epoch: 2, num_updates: 800, iterations: 800, max_updates: 3000, lr: 0.00002, ups: 0.79, time: 01m 03s 014ms, time_since_start: 17m 54s 106ms, eta: 49m 21s 155ms\n",
      "\u001b[32m2021-11-30T14:12:31 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 850/3000, train/hateful_memes/cross_entropy: 0.5794, train/hateful_memes/cross_entropy/avg: 0.5667, train/total_loss: 0.5794, train/total_loss/avg: 0.5667, max mem: 5497.0, experiment: run, epoch: 2, num_updates: 850, iterations: 850, max_updates: 3000, lr: 0.00002, ups: 0.79, time: 01m 03s 119ms, time_since_start: 18m 57s 226ms, eta: 48m 18s 718ms\n",
      "\u001b[32m2021-11-30T14:18:53 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1100/3000, train/hateful_memes/cross_entropy: 0.5369, train/hateful_memes/cross_entropy/avg: 0.5248, train/total_loss: 0.5369, train/total_loss/avg: 0.5248, max mem: 5497.0, experiment: run, epoch: 3, num_updates: 1100, iterations: 1100, max_updates: 3000, lr: 0.00003, ups: 0.81, time: 01m 02s 303ms, time_since_start: 25m 18s 711ms, eta: 42m 08s 528ms\n",
      "\u001b[32m2021-11-30T14:19:56 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1150/3000, train/hateful_memes/cross_entropy: 0.5296, train/hateful_memes/cross_entropy/avg: 0.5231, train/total_loss: 0.5296, train/total_loss/avg: 0.5231, max mem: 5497.0, experiment: run, epoch: 3, num_updates: 1150, iterations: 1150, max_updates: 3000, lr: 0.00003, ups: 0.79, time: 01m 03s 320ms, time_since_start: 26m 22s 032ms, eta: 41m 42s 187ms\n",
      "\u001b[32m2021-11-30T14:20:59 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1200/3000, train/hateful_memes/cross_entropy: 0.4869, train/hateful_memes/cross_entropy/avg: 0.5196, train/total_loss: 0.4869, train/total_loss/avg: 0.5196, max mem: 5497.0, experiment: run, epoch: 3, num_updates: 1200, iterations: 1200, max_updates: 3000, lr: 0.00003, ups: 0.79, time: 01m 03s 147ms, time_since_start: 27m 25s 179ms, eta: 40m 27s 897ms\n",
      "\u001b[32m2021-11-30T14:22:03 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1250/3000, train/hateful_memes/cross_entropy: 0.4627, train/hateful_memes/cross_entropy/avg: 0.5114, train/total_loss: 0.4627, train/total_loss/avg: 0.5114, max mem: 5497.0, experiment: run, epoch: 3, num_updates: 1250, iterations: 1250, max_updates: 3000, lr: 0.00003, ups: 0.79, time: 01m 03s 230ms, time_since_start: 28m 28s 409ms, eta: 39m 23s 538ms\n",
      "\u001b[32m2021-11-30T14:23:06 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1300/3000, train/hateful_memes/cross_entropy: 0.4529, train/hateful_memes/cross_entropy/avg: 0.4975, train/total_loss: 0.4529, train/total_loss/avg: 0.4975, max mem: 5497.0, experiment: run, epoch: 3, num_updates: 1300, iterations: 1300, max_updates: 3000, lr: 0.00003, ups: 0.79, time: 01m 03s 115ms, time_since_start: 29m 31s 525ms, eta: 38m 11s 849ms\n",
      "\u001b[32m2021-11-30T14:24:09 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1350/3000, train/hateful_memes/cross_entropy: 0.4392, train/hateful_memes/cross_entropy/avg: 0.4900, train/total_loss: 0.4392, train/total_loss/avg: 0.4900, max mem: 5497.0, experiment: run, epoch: 3, num_updates: 1350, iterations: 1350, max_updates: 3000, lr: 0.00003, ups: 0.79, time: 01m 03s 211ms, time_since_start: 30m 34s 737ms, eta: 37m 07s 831ms\n",
      "\u001b[32m2021-11-30T14:25:12 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1400/3000, train/hateful_memes/cross_entropy: 0.4392, train/hateful_memes/cross_entropy/avg: 0.4919, train/total_loss: 0.4392, train/total_loss/avg: 0.4919, max mem: 5497.0, experiment: run, epoch: 3, num_updates: 1400, iterations: 1400, max_updates: 3000, lr: 0.00003, ups: 0.79, time: 01m 03s 117ms, time_since_start: 31m 37s 854ms, eta: 35m 57s 091ms\n",
      "\u001b[32m2021-11-30T14:26:15 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1450/3000, train/hateful_memes/cross_entropy: 0.4392, train/hateful_memes/cross_entropy/avg: 0.5013, train/total_loss: 0.4392, train/total_loss/avg: 0.5013, max mem: 5497.0, experiment: run, epoch: 3, num_updates: 1450, iterations: 1450, max_updates: 3000, lr: 0.00004, ups: 0.79, time: 01m 03s 271ms, time_since_start: 32m 41s 125ms, eta: 34m 54s 782ms\n",
      "\u001b[32m2021-11-30T14:27:18 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1500/3000, train/hateful_memes/cross_entropy: 0.4529, train/hateful_memes/cross_entropy/avg: 0.5071, train/total_loss: 0.4529, train/total_loss/avg: 0.5071, max mem: 5497.0, experiment: run, epoch: 3, num_updates: 1500, iterations: 1500, max_updates: 3000, lr: 0.00004, ups: 0.79, time: 01m 03s 116ms, time_since_start: 33m 44s 242ms, eta: 33m 42s 266ms\n",
      "\u001b[32m2021-11-30T14:27:18 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
      "\u001b[32m2021-11-30T14:27:18 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
      "\u001b[32m2021-11-30T14:27:33 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished training. Loaded 34\n",
      "\u001b[32m2021-11-30T14:27:33 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
      "\u001b[32m2021-11-30T14:27:34 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
      "\u001b[32m2021-11-30T14:27:36 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
      "\u001b[32m2021-11-30T14:27:48 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
      "\u001b[32m2021-11-30T14:33:16 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1750/3000, train/hateful_memes/cross_entropy: 0.3181, train/hateful_memes/cross_entropy/avg: 0.4684, train/total_loss: 0.3181, train/total_loss/avg: 0.4684, max mem: 5497.0, experiment: run, epoch: 4, num_updates: 1750, iterations: 1750, max_updates: 3000, lr: 0.00004, ups: 0.79, time: 01m 03s 037ms, time_since_start: 39m 41s 707ms, eta: 28m 03s 104ms\n",
      "\u001b[32m2021-11-30T14:34:19 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1800/3000, train/hateful_memes/cross_entropy: 0.3181, train/hateful_memes/cross_entropy/avg: 0.4688, train/total_loss: 0.3181, train/total_loss/avg: 0.4688, max mem: 5497.0, experiment: run, epoch: 4, num_updates: 1800, iterations: 1800, max_updates: 3000, lr: 0.00005, ups: 0.81, time: 01m 02s 984ms, time_since_start: 40m 44s 692ms, eta: 26m 54s 418ms\n",
      "\u001b[32m2021-11-30T14:35:22 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1850/3000, train/hateful_memes/cross_entropy: 0.3142, train/hateful_memes/cross_entropy/avg: 0.4641, train/total_loss: 0.3142, train/total_loss/avg: 0.4641, max mem: 5497.0, experiment: run, epoch: 4, num_updates: 1850, iterations: 1850, max_updates: 3000, lr: 0.00005, ups: 0.79, time: 01m 03s 071ms, time_since_start: 41m 47s 763ms, eta: 25m 49s 293ms\n",
      "\u001b[32m2021-11-30T14:36:25 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1900/3000, train/hateful_memes/cross_entropy: 0.3126, train/hateful_memes/cross_entropy/avg: 0.4601, train/total_loss: 0.3126, train/total_loss/avg: 0.4601, max mem: 5497.0, experiment: run, epoch: 4, num_updates: 1900, iterations: 1900, max_updates: 3000, lr: 0.00005, ups: 0.81, time: 01m 02s 927ms, time_since_start: 42m 50s 690ms, eta: 24m 38s 538ms\n",
      "\u001b[32m2021-11-30T14:37:28 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1950/3000, train/hateful_memes/cross_entropy: 0.3142, train/hateful_memes/cross_entropy/avg: 0.4604, train/total_loss: 0.3142, train/total_loss/avg: 0.4604, max mem: 5497.0, experiment: run, epoch: 4, num_updates: 1950, iterations: 1950, max_updates: 3000, lr: 0.00005, ups: 0.79, time: 01m 03s 071ms, time_since_start: 43m 53s 762ms, eta: 23m 34s 568ms\n",
      "\u001b[32m2021-11-30T14:38:31 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
      "\u001b[32m2021-11-30T14:38:31 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
      "\u001b[32m2021-11-30T14:38:33 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
      "\u001b[32m2021-11-30T14:38:46 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
      "\u001b[32m2021-11-30T14:38:46 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2000/3000, train/hateful_memes/cross_entropy: 0.3142, train/hateful_memes/cross_entropy/avg: 0.4600, train/total_loss: 0.3142, train/total_loss/avg: 0.4600, max mem: 5497.0, experiment: run, epoch: 4, num_updates: 2000, iterations: 2000, max_updates: 3000, lr: 0.00005, ups: 0.65, time: 01m 17s 931ms, time_since_start: 45m 11s 694ms, eta: 27m 44s 627ms\n",
      "\u001b[32m2021-11-30T14:38:46 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
      "\u001b[32m2021-11-30T14:38:46 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
      "\u001b[32m2021-11-30T14:39:01 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished training. Loaded 34\n",
      "\u001b[32m2021-11-30T14:39:01 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
      "\u001b[32m2021-11-30T14:39:01 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
      "\u001b[32m2021-11-30T14:39:14 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
      "\u001b[32m2021-11-30T14:39:27 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
      "\u001b[32m2021-11-30T14:39:39 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
      "\u001b[32m2021-11-30T14:39:39 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2000/3000, val/hateful_memes/cross_entropy: 0.7751, val/total_loss: 0.7751, val/hateful_memes/accuracy: 0.7037, val/hateful_memes/binary_f1: 0.4839, val/hateful_memes/roc_auc: 0.7074, num_updates: 2000, epoch: 4, iterations: 2000, max_updates: 3000, val_time: 53s 138ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.707397\n",
      "\u001b[32m2021-11-30T14:40:43 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2050/3000, train/hateful_memes/cross_entropy: 0.3126, train/hateful_memes/cross_entropy/avg: 0.4551, train/total_loss: 0.3126, train/total_loss/avg: 0.4551, max mem: 5497.0, experiment: run, epoch: 4, num_updates: 2050, iterations: 2050, max_updates: 3000, lr: 0.00005, ups: 0.79, time: 01m 03s 456ms, time_since_start: 47m 08s 291ms, eta: 21m 27s 657ms\n",
      "\u001b[32m2021-11-30T14:41:45 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2100/3000, train/hateful_memes/cross_entropy: 0.3142, train/hateful_memes/cross_entropy/avg: 0.4530, train/total_loss: 0.3142, train/total_loss/avg: 0.4530, max mem: 5497.0, experiment: run, epoch: 4, num_updates: 2100, iterations: 2100, max_updates: 3000, lr: 0.00005, ups: 0.81, time: 01m 02s 934ms, time_since_start: 48m 11s 225ms, eta: 20m 09s 850ms\n",
      "\u001b[32m2021-11-30T14:42:48 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2150/3000, train/hateful_memes/cross_entropy: 0.3126, train/hateful_memes/cross_entropy/avg: 0.4436, train/total_loss: 0.3126, train/total_loss/avg: 0.4436, max mem: 5497.0, experiment: run, epoch: 5, num_updates: 2150, iterations: 2150, max_updates: 3000, lr: 0.00004, ups: 0.81, time: 01m 02s 189ms, time_since_start: 49m 13s 414ms, eta: 18m 49s 110ms\n",
      "\u001b[32m2021-11-30T14:43:51 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2200/3000, train/hateful_memes/cross_entropy: 0.3126, train/hateful_memes/cross_entropy/avg: 0.4433, train/total_loss: 0.3126, train/total_loss/avg: 0.4433, max mem: 5497.0, experiment: run, epoch: 5, num_updates: 2200, iterations: 2200, max_updates: 3000, lr: 0.00004, ups: 0.81, time: 01m 02s 902ms, time_since_start: 50m 16s 317ms, eta: 17m 54s 882ms\n",
      "\u001b[32m2021-11-30T14:44:54 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2250/3000, train/hateful_memes/cross_entropy: 0.2969, train/hateful_memes/cross_entropy/avg: 0.4393, train/total_loss: 0.2969, train/total_loss/avg: 0.4393, max mem: 5497.0, experiment: run, epoch: 5, num_updates: 2250, iterations: 2250, max_updates: 3000, lr: 0.00004, ups: 0.79, time: 01m 03s 064ms, time_since_start: 51m 19s 382ms, eta: 16m 50s 300ms\n",
      "\u001b[32m2021-11-30T14:45:57 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2300/3000, train/hateful_memes/cross_entropy: 0.2969, train/hateful_memes/cross_entropy/avg: 0.4314, train/total_loss: 0.2969, train/total_loss/avg: 0.4314, max mem: 5497.0, experiment: run, epoch: 5, num_updates: 2300, iterations: 2300, max_updates: 3000, lr: 0.00003, ups: 0.81, time: 01m 02s 931ms, time_since_start: 52m 22s 314ms, eta: 15m 40s 949ms\n",
      "\u001b[32m2021-11-30T14:47:00 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2350/3000, train/hateful_memes/cross_entropy: 0.2938, train/hateful_memes/cross_entropy/avg: 0.4227, train/total_loss: 0.2938, train/total_loss/avg: 0.4227, max mem: 5497.0, experiment: run, epoch: 5, num_updates: 2350, iterations: 2350, max_updates: 3000, lr: 0.00003, ups: 0.81, time: 01m 02s 983ms, time_since_start: 53m 25s 297ms, eta: 14m 34s 463ms\n",
      "\u001b[32m2021-11-30T14:48:02 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2400/3000, train/hateful_memes/cross_entropy: 0.2813, train/hateful_memes/cross_entropy/avg: 0.4145, train/total_loss: 0.2813, train/total_loss/avg: 0.4145, max mem: 5497.0, experiment: run, epoch: 5, num_updates: 2400, iterations: 2400, max_updates: 3000, lr: 0.00003, ups: 0.81, time: 01m 02s 954ms, time_since_start: 54m 28s 251ms, eta: 13m 26s 821ms\n",
      "\u001b[32m2021-11-30T14:49:06 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2450/3000, train/hateful_memes/cross_entropy: 0.2641, train/hateful_memes/cross_entropy/avg: 0.4067, train/total_loss: 0.2641, train/total_loss/avg: 0.4067, max mem: 5497.0, experiment: run, epoch: 5, num_updates: 2450, iterations: 2450, max_updates: 3000, lr: 0.00003, ups: 0.79, time: 01m 03s 007ms, time_since_start: 55m 31s 259ms, eta: 12m 20s 213ms\n",
      "\u001b[32m2021-11-30T14:50:08 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2500/3000, train/hateful_memes/cross_entropy: 0.2611, train/hateful_memes/cross_entropy/avg: 0.3988, train/total_loss: 0.2611, train/total_loss/avg: 0.3988, max mem: 5497.0, experiment: run, epoch: 5, num_updates: 2500, iterations: 2500, max_updates: 3000, lr: 0.00003, ups: 0.81, time: 01m 02s 918ms, time_since_start: 56m 34s 178ms, eta: 11m 11s 971ms\n",
      "\u001b[32m2021-11-30T14:50:08 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
      "\u001b[32m2021-11-30T14:50:08 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
      "\u001b[32m2021-11-30T14:50:23 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished training. Loaded 34\n",
      "\u001b[32m2021-11-30T14:50:23 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
      "\u001b[32m2021-11-30T14:50:24 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
      "\u001b[32m2021-11-30T14:50:26 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
      "\u001b[32m2021-11-30T14:50:39 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
      "\u001b[32m2021-11-30T14:51:01 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
      "\u001b[32m2021-11-30T14:51:01 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2500/3000, val/hateful_memes/cross_entropy: 0.9755, val/total_loss: 0.9755, val/hateful_memes/accuracy: 0.6796, val/hateful_memes/binary_f1: 0.5506, val/hateful_memes/roc_auc: 0.7126, num_updates: 2500, epoch: 5, iterations: 2500, max_updates: 3000, val_time: 52s 688ms, best_update: 2500, best_iteration: 2500, best_val/hateful_memes/roc_auc: 0.712574\n",
      "\u001b[32m2021-11-30T14:52:05 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2550/3000, train/hateful_memes/cross_entropy: 0.2611, train/hateful_memes/cross_entropy/avg: 0.3977, train/total_loss: 0.2611, train/total_loss/avg: 0.3977, max mem: 5497.0, experiment: run, epoch: 5, num_updates: 2550, iterations: 2550, max_updates: 3000, lr: 0.00002, ups: 0.79, time: 01m 03s 502ms, time_since_start: 58m 30s 384ms, eta: 10m 10s 389ms\n",
      "\u001b[32m2021-11-30T14:53:08 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2600/3000, train/hateful_memes/cross_entropy: 0.2562, train/hateful_memes/cross_entropy/avg: 0.3934, train/total_loss: 0.2562, train/total_loss/avg: 0.3934, max mem: 5497.0, experiment: run, epoch: 5, num_updates: 2600, iterations: 2600, max_updates: 3000, lr: 0.00002, ups: 0.81, time: 01m 02s 923ms, time_since_start: 59m 33s 307ms, eta: 08m 57s 615ms\n",
      "\u001b[32m2021-11-30T14:54:11 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2650/3000, train/hateful_memes/cross_entropy: 0.2188, train/hateful_memes/cross_entropy/avg: 0.3897, train/total_loss: 0.2188, train/total_loss/avg: 0.3897, max mem: 5497.0, experiment: run, epoch: 5, num_updates: 2650, iterations: 2650, max_updates: 3000, lr: 0.00002, ups: 0.81, time: 01m 02s 999ms, time_since_start: 01h 36s 307ms, eta: 07m 50s 985ms\n",
      "\u001b[32m2021-11-30T14:55:12 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2700/3000, train/hateful_memes/cross_entropy: 0.2188, train/hateful_memes/cross_entropy/avg: 0.3836, train/total_loss: 0.2188, train/total_loss/avg: 0.3836, max mem: 5497.0, experiment: run, epoch: 6, num_updates: 2700, iterations: 2700, max_updates: 3000, lr: 0.00002, ups: 0.82, time: 01m 01s 894ms, time_since_start: 01h 01m 38s 201ms, eta: 06m 36s 619ms\n",
      "\u001b[32m2021-11-30T14:56:15 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2750/3000, train/hateful_memes/cross_entropy: 0.1980, train/hateful_memes/cross_entropy/avg: 0.3769, train/total_loss: 0.1980, train/total_loss/avg: 0.3769, max mem: 5497.0, experiment: run, epoch: 6, num_updates: 2750, iterations: 2750, max_updates: 3000, lr: 0.00001, ups: 0.81, time: 01m 02s 786ms, time_since_start: 01h 02m 40s 987ms, eta: 05m 35s 277ms\n",
      "\u001b[32m2021-11-30T14:57:18 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2800/3000, train/hateful_memes/cross_entropy: 0.1714, train/hateful_memes/cross_entropy/avg: 0.3703, train/total_loss: 0.1714, train/total_loss/avg: 0.3703, max mem: 5497.0, experiment: run, epoch: 6, num_updates: 2800, iterations: 2800, max_updates: 3000, lr: 0.00001, ups: 0.81, time: 01m 02s 750ms, time_since_start: 01h 03m 43s 738ms, eta: 04m 28s 069ms\n",
      "\u001b[32m2021-11-30T14:58:21 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2850/3000, train/hateful_memes/cross_entropy: 0.0768, train/hateful_memes/cross_entropy/avg: 0.3639, train/total_loss: 0.0768, train/total_loss/avg: 0.3639, max mem: 5497.0, experiment: run, epoch: 6, num_updates: 2850, iterations: 2850, max_updates: 3000, lr: 0.00001, ups: 0.81, time: 01m 02s 878ms, time_since_start: 01h 04m 46s 616ms, eta: 03m 21s 463ms\n",
      "\u001b[32m2021-11-30T14:59:24 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2900/3000, train/hateful_memes/cross_entropy: 0.0584, train/hateful_memes/cross_entropy/avg: 0.3585, train/total_loss: 0.0584, train/total_loss/avg: 0.3585, max mem: 5497.0, experiment: run, epoch: 6, num_updates: 2900, iterations: 2900, max_updates: 3000, lr: 0.00001, ups: 0.81, time: 01m 02s 698ms, time_since_start: 01h 05m 49s 314ms, eta: 02m 13s 923ms\n",
      "\u001b[32m2021-11-30T15:00:26 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2950/3000, train/hateful_memes/cross_entropy: 0.0513, train/hateful_memes/cross_entropy/avg: 0.3525, train/total_loss: 0.0513, train/total_loss/avg: 0.3525, max mem: 5497.0, experiment: run, epoch: 6, num_updates: 2950, iterations: 2950, max_updates: 3000, lr: 0., ups: 0.81, time: 01m 02s 821ms, time_since_start: 01h 06m 52s 136ms, eta: 01m 07s 093ms\n",
      "\u001b[32m2021-11-30T15:01:29 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
      "\u001b[32m2021-11-30T15:01:29 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
      "\u001b[32m2021-11-30T15:01:31 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
      "\u001b[32m2021-11-30T15:01:45 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
      "\u001b[32m2021-11-30T15:01:45 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3000/3000, train/hateful_memes/cross_entropy: 0.0503, train/hateful_memes/cross_entropy/avg: 0.3469, train/total_loss: 0.0503, train/total_loss/avg: 0.3469, max mem: 5497.0, experiment: run, epoch: 6, num_updates: 3000, iterations: 3000, max_updates: 3000, lr: 0., ups: 0.64, time: 01m 18s 748ms, time_since_start: 01h 08m 10s 885ms, eta: 0ms\n",
      "\u001b[32m2021-11-30T15:01:45 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
      "\u001b[32m2021-11-30T15:01:45 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
      "\u001b[32m2021-11-30T15:02:00 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished training. Loaded 34\n",
      "\u001b[32m2021-11-30T15:02:00 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
      "\u001b[32m2021-11-30T15:02:01 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
      "\u001b[32m2021-11-30T15:02:13 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
      "\u001b[32m2021-11-30T15:02:26 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
      "\u001b[32m2021-11-30T15:02:39 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
      "\u001b[32m2021-11-30T15:02:39 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3000/3000, val/hateful_memes/cross_entropy: 1.4779, val/total_loss: 1.4779, val/hateful_memes/accuracy: 0.6907, val/hateful_memes/binary_f1: 0.5045, val/hateful_memes/roc_auc: 0.7273, num_updates: 3000, epoch: 6, iterations: 3000, max_updates: 3000, val_time: 53s 886ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.727334\n",
      "\u001b[32m2021-11-30T15:02:40 | mmf.trainers.core.training_loop: \u001b[0mStepping into final validation check\n",
      "\u001b[32m2021-11-30T15:02:40 | mmf.utils.checkpoint: \u001b[0mRestoring checkpoint\n",
      "\u001b[32m2021-11-30T15:02:40 | mmf.utils.checkpoint: \u001b[0mLoading checkpoint\n",
      "\u001b[32m2021-11-30T15:02:40 | mmf.utils.checkpoint: \u001b[0mCheckpoint loaded.\n",
      "\u001b[32m2021-11-30T15:02:40 | mmf.utils.checkpoint: \u001b[0mCurrent num updates: 3000\n",
      "\u001b[32m2021-11-30T15:02:40 | mmf.utils.checkpoint: \u001b[0mCurrent iteration: 3000\n",
      "\u001b[32m2021-11-30T15:02:40 | mmf.utils.checkpoint: \u001b[0mCurrent epoch: 6\n",
      "\u001b[32m2021-11-30T15:02:41 | mmf.trainers.mmf_trainer: \u001b[0mStarting inference on test set\n",
      "\u001b[32m2021-11-30T15:02:41 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
      "100%|| 125/125 [01:47<00:00,  1.16it/s]\n",
      "\u001b[32m2021-11-30T15:04:29 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished training. Loaded 125\n",
      "\u001b[32m2021-11-30T15:04:29 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
      "\u001b[32m2021-11-30T15:04:29 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3000/3000, test/hateful_memes/cross_entropy: 1.3683, test/total_loss: 1.3683, test/hateful_memes/accuracy: 0.7215, test/hateful_memes/binary_f1: 0.5354, test/hateful_memes/roc_auc: 0.7681\n",
      "\u001b[32m2021-11-30T15:04:29 | mmf.trainers.callbacks.logistics: \u001b[0mFinished run in 01h 10m 55s 029ms\n"
     ]
    }
   ],
   "source": [
    "!mmf_run config=projects/hateful_memes/configs/visual_bert/from_coco.yaml \\\n",
    "  model=visual_bert \\\n",
    "  dataset=hateful_memes \\\n",
    "  training.log_interval=50 \\\n",
    "  training.max_updates=3000 \\\n",
    "  training.batch_size=16 \\\n",
    "  training.evaluation_interval=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23422414-7f50-46a0-bb2b-6490031c9f55",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.7/site-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_USER_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
      "  category=UserWarning,\n",
      "/home/jupyter/.local/lib/python3.7/site-packages/omegaconf/resolvers/__init__.py:13: UserWarning: The `env` resolver is deprecated, see https://github.com/omry/omegaconf/issues/573\n",
      "  \"The `env` resolver is deprecated, see https://github.com/omry/omegaconf/issues/573\"\n",
      "\u001b[32m2021-11-30T18:23:56 | mmf.utils.configuration: \u001b[0mOverriding option config to projects/hateful_memes/configs/vilbert/from_cc.yaml\n",
      "\u001b[32m2021-11-30T18:23:56 | mmf.utils.configuration: \u001b[0mOverriding option model to vilbert\n",
      "\u001b[32m2021-11-30T18:23:56 | mmf.utils.configuration: \u001b[0mOverriding option datasets to hateful_memes\n",
      "\u001b[32m2021-11-30T18:23:56 | mmf.utils.configuration: \u001b[0mOverriding option training.log_interval to 50\n",
      "\u001b[32m2021-11-30T18:23:56 | mmf.utils.configuration: \u001b[0mOverriding option training.max_updates to 3000\n",
      "\u001b[32m2021-11-30T18:23:56 | mmf.utils.configuration: \u001b[0mOverriding option training.batch_size to 16\n",
      "\u001b[32m2021-11-30T18:23:56 | mmf.utils.configuration: \u001b[0mOverriding option training.evaluation_interval to 500\n",
      "/home/jupyter/.local/lib/python3.7/site-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_LOG_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
      "  category=UserWarning,\n",
      "/home/jupyter/.local/lib/python3.7/site-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_REPORT_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
      "  category=UserWarning,\n",
      "/home/jupyter/.local/lib/python3.7/site-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_TENSORBOARD_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
      "  category=UserWarning,\n",
      "/home/jupyter/.local/lib/python3.7/site-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_WANDB_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
      "  category=UserWarning,\n",
      "\u001b[32m2021-11-30T18:23:56 | mmf: \u001b[0mLogging to: ./save/train.log\n",
      "\u001b[32m2021-11-30T18:23:56 | mmf_cli.run: \u001b[0mNamespace(config_override=None, local_rank=None, opts=['config=projects/hateful_memes/configs/vilbert/from_cc.yaml', 'model=vilbert', 'dataset=hateful_memes', 'training.log_interval=50', 'training.max_updates=3000', 'training.batch_size=16', 'training.evaluation_interval=500'])\n",
      "\u001b[32m2021-11-30T18:23:56 | mmf_cli.run: \u001b[0mTorch version: 1.9.0+cu102\n",
      "\u001b[32m2021-11-30T18:23:56 | mmf.utils.general: \u001b[0mCUDA Device 0 is: Tesla K80\n",
      "\u001b[32m2021-11-30T18:23:56 | mmf_cli.run: \u001b[0mUsing seed 56748593\n",
      "\u001b[32m2021-11-30T18:23:56 | mmf.trainers.mmf_trainer: \u001b[0mLoading datasets\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/jupyter/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.10.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/jupyter/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/jupyter/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/jupyter/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/jupyter/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.10.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "\u001b[32m2021-11-30T18:23:59 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
      "\u001b[32m2021-11-30T18:23:59 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
      "\u001b[32m2021-11-30T18:23:59 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
      "\u001b[32m2021-11-30T18:23:59 | mmf.trainers.mmf_trainer: \u001b[0mLoading model\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bert_model_name\": \"bert-base-uncased\",\n",
      "  \"bi_attention_type\": 1,\n",
      "  \"bi_hidden_size\": 1024,\n",
      "  \"bi_intermediate_size\": 1024,\n",
      "  \"bi_num_attention_heads\": 8,\n",
      "  \"bypass_transformer\": false,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"cut_first\": \"text\",\n",
      "  \"dynamic_attention\": false,\n",
      "  \"embedding_strategy\": \"plain\",\n",
      "  \"fast_mode\": false,\n",
      "  \"finetune_lr_multiplier\": 1,\n",
      "  \"fixed_t_layer\": 0,\n",
      "  \"fixed_v_layer\": 0,\n",
      "  \"freeze_base\": false,\n",
      "  \"fusion_method\": \"mul\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hard_cap_seq_len\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"in_batch_pairs\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"losses\": [\n",
      "    \"cross_entropy\"\n",
      "  ],\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model\": \"vilbert\",\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_negative\": 128,\n",
      "  \"objective\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_method\": \"mul\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"random_initialize\": false,\n",
      "  \"special_visual_initialize\": true,\n",
      "  \"t_biattention_id\": [\n",
      "    6,\n",
      "    7,\n",
      "    8,\n",
      "    9,\n",
      "    10,\n",
      "    11\n",
      "  ],\n",
      "  \"task_specific_tokens\": false,\n",
      "  \"text_only\": false,\n",
      "  \"training_head_type\": \"classification\",\n",
      "  \"transformers_version\": \"4.10.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"v_attention_probs_dropout_prob\": 0.1,\n",
      "  \"v_biattention_id\": [\n",
      "    0,\n",
      "    1,\n",
      "    2,\n",
      "    3,\n",
      "    4,\n",
      "    5\n",
      "  ],\n",
      "  \"v_feature_size\": 2048,\n",
      "  \"v_hidden_act\": \"gelu\",\n",
      "  \"v_hidden_dropout_prob\": 0.1,\n",
      "  \"v_hidden_size\": 1024,\n",
      "  \"v_initializer_range\": 0.02,\n",
      "  \"v_intermediate_size\": 1024,\n",
      "  \"v_num_attention_heads\": 8,\n",
      "  \"v_num_hidden_layers\": 6,\n",
      "  \"v_target_size\": 1601,\n",
      "  \"visual_embedding_dim\": 2048,\n",
      "  \"visual_target\": 0,\n",
      "  \"visualization\": false,\n",
      "  \"vocab_size\": 30522,\n",
      "  \"with_coattention\": true\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/jupyter/.cache/torch/mmf/distributed_-1/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing ViLBERTBase: ['bert.pooler.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'bert.pooler.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing ViLBERTBase from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViLBERTBase from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViLBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.v_layer.0.attention.output.LayerNorm.weight', 'bert.encoder.c_layer.5.biOutput.q_dense2.bias', 'bert.encoder.c_layer.3.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.1.biattention.query1.weight', 'bert.encoder.c_layer.2.biOutput.q_dense2.weight', 'bert.encoder.c_layer.0.biattention.key2.weight', 'bert.encoder.c_layer.5.t_output.dense.weight', 'bert.encoder.c_layer.3.biattention.query1.weight', 'bert.encoder.v_layer.2.output.LayerNorm.bias', 'bert.encoder.c_layer.3.biOutput.dense1.bias', 'bert.encoder.c_layer.1.t_output.dense.bias', 'bert.encoder.c_layer.2.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.5.biattention.query2.bias', 'bert.encoder.v_layer.3.attention.output.LayerNorm.bias', 'bert.encoder.c_layer.4.biattention.query1.bias', 'bert.encoder.c_layer.3.biattention.query2.weight', 'bert.encoder.c_layer.4.biOutput.q_dense2.weight', 'bert.encoder.c_layer.1.biOutput.q_dense1.bias', 'bert.encoder.c_layer.2.biattention.query1.bias', 'bert.t_pooler.dense.bias', 'bert.encoder.v_layer.4.attention.output.LayerNorm.bias', 'bert.encoder.c_layer.2.biattention.key1.weight', 'bert.encoder.c_layer.4.t_output.LayerNorm.bias', 'bert.encoder.c_layer.0.v_output.LayerNorm.weight', 'bert.encoder.c_layer.3.biattention.query1.bias', 'bert.encoder.v_layer.5.attention.output.LayerNorm.weight', 'bert.encoder.c_layer.0.biOutput.dense1.bias', 'bert.encoder.v_layer.0.intermediate.dense.weight', 'bert.encoder.c_layer.3.biattention.value1.weight', 'bert.encoder.c_layer.5.t_intermediate.dense.weight', 'bert.encoder.v_layer.3.attention.self.query.bias', 'bert.encoder.v_layer.2.attention.self.value.bias', 'bert.encoder.v_layer.5.attention.output.LayerNorm.bias', 'bert.encoder.c_layer.0.v_output.LayerNorm.bias', 'bert.encoder.c_layer.3.biOutput.dense2.bias', 'bert.encoder.v_layer.4.attention.self.value.weight', 'bert.encoder.v_layer.2.output.dense.weight', 'bert.encoder.c_layer.1.biattention.key2.weight', 'bert.encoder.v_layer.4.intermediate.dense.bias', 'bert.encoder.v_layer.4.attention.self.query.weight', 'bert.encoder.v_layer.3.intermediate.dense.bias', 'bert.encoder.c_layer.1.t_intermediate.dense.weight', 'bert.encoder.v_layer.0.attention.output.LayerNorm.bias', 'bert.encoder.c_layer.4.biOutput.LayerNorm2.bias', 'bert.encoder.v_layer.3.output.dense.bias', 'bert.encoder.c_layer.5.t_intermediate.dense.bias', 'bert.encoder.c_layer.3.biattention.key1.weight', 'bert.encoder.v_layer.0.attention.self.value.bias', 'bert.encoder.v_layer.3.attention.self.query.weight', 'bert.encoder.v_layer.5.attention.self.query.bias', 'bert.encoder.c_layer.1.t_output.dense.weight', 'bert.encoder.c_layer.5.biOutput.q_dense1.bias', 'bert.encoder.c_layer.5.v_intermediate.dense.bias', 'bert.encoder.c_layer.2.t_output.dense.bias', 'bert.encoder.v_layer.1.attention.self.value.weight', 'bert.encoder.c_layer.1.v_intermediate.dense.weight', 'bert.encoder.v_layer.5.attention.self.key.weight', 'bert.encoder.c_layer.2.biattention.value1.bias', 'bert.encoder.v_layer.5.attention.self.key.bias', 'bert.encoder.c_layer.1.t_output.LayerNorm.bias', 'bert.encoder.v_layer.4.attention.self.value.bias', 'bert.encoder.v_layer.5.output.dense.bias', 'bert.encoder.c_layer.2.t_output.LayerNorm.bias', 'bert.encoder.c_layer.0.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.2.biattention.value2.bias', 'bert.encoder.c_layer.0.t_intermediate.dense.bias', 'bert.encoder.v_layer.0.intermediate.dense.bias', 'bert.encoder.v_layer.4.output.dense.weight', 'bert.encoder.v_layer.3.attention.output.dense.weight', 'bert.encoder.c_layer.0.biattention.value1.weight', 'bert.encoder.c_layer.5.v_output.LayerNorm.weight', 'bert.encoder.c_layer.5.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.2.biattention.query2.bias', 'bert.v_embeddings.image_embeddings.bias', 'bert.encoder.v_layer.0.attention.self.key.bias', 'bert.encoder.c_layer.4.biattention.value1.weight', 'bert.encoder.c_layer.4.t_intermediate.dense.weight', 'bert.encoder.v_layer.0.attention.self.query.weight', 'bert.encoder.c_layer.4.biOutput.dense2.bias', 'bert.encoder.v_layer.4.attention.output.dense.weight', 'bert.encoder.c_layer.0.biattention.key1.bias', 'bert.encoder.c_layer.0.biattention.key1.weight', 'bert.encoder.c_layer.4.v_output.dense.weight', 'bert.encoder.c_layer.5.biOutput.dense2.bias', 'bert.encoder.c_layer.4.v_intermediate.dense.bias', 'bert.encoder.c_layer.1.t_intermediate.dense.bias', 'bert.encoder.v_layer.0.output.LayerNorm.bias', 'bert.encoder.c_layer.4.biattention.key2.bias', 'bert.encoder.c_layer.0.t_intermediate.dense.weight', 'bert.encoder.v_layer.0.attention.output.dense.bias', 'bert.encoder.c_layer.0.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.1.biattention.key1.bias', 'bert.encoder.v_layer.3.attention.self.key.weight', 'bert.encoder.v_layer.5.attention.self.query.weight', 'bert.encoder.v_layer.5.attention.self.value.weight', 'bert.encoder.c_layer.0.biattention.value2.weight', 'bert.encoder.c_layer.2.t_intermediate.dense.bias', 'bert.encoder.c_layer.5.biOutput.dense1.bias', 'bert.encoder.c_layer.3.v_output.dense.bias', 'bert.encoder.c_layer.0.biOutput.q_dense1.weight', 'bert.encoder.c_layer.3.biOutput.q_dense2.weight', 'bert.encoder.c_layer.2.v_intermediate.dense.bias', 'bert.encoder.c_layer.3.biOutput.LayerNorm2.weight', 'bert.encoder.v_layer.2.attention.output.LayerNorm.weight', 'bert.encoder.c_layer.4.biOutput.q_dense1.weight', 'bert.encoder.c_layer.2.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.1.biattention.value1.weight', 'bert.encoder.c_layer.3.biattention.value2.bias', 'bert.encoder.c_layer.1.biattention.query2.bias', 'bert.encoder.c_layer.5.biattention.query1.bias', 'bert.encoder.c_layer.1.biOutput.LayerNorm2.bias', 'bert.encoder.v_layer.1.attention.output.LayerNorm.weight', 'bert.encoder.c_layer.5.biattention.key1.bias', 'bert.encoder.c_layer.1.t_output.LayerNorm.weight', 'bert.encoder.v_layer.5.intermediate.dense.bias', 'bert.encoder.c_layer.2.v_output.dense.bias', 'bert.encoder.c_layer.3.v_output.LayerNorm.bias', 'bert.encoder.c_layer.4.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.1.biOutput.dense2.bias', 'bert.encoder.c_layer.0.biOutput.dense2.weight', 'bert.encoder.c_layer.2.t_output.dense.weight', 'bert.encoder.c_layer.5.biattention.value2.weight', 'bert.encoder.v_layer.2.intermediate.dense.bias', 'bert.encoder.c_layer.2.biOutput.dense1.bias', 'bert.encoder.v_layer.2.attention.self.query.bias', 'bert.encoder.v_layer.0.attention.self.key.weight', 'bert.encoder.c_layer.0.biattention.query1.bias', 'bert.encoder.v_layer.3.attention.output.LayerNorm.weight', 'bert.encoder.c_layer.2.v_output.dense.weight', 'bert.encoder.c_layer.0.biattention.value2.bias', 'bert.encoder.c_layer.3.biOutput.LayerNorm2.bias', 'bert.encoder.v_layer.0.output.dense.bias', 'bert.encoder.c_layer.4.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.4.biOutput.dense2.weight', 'bert.encoder.c_layer.4.biOutput.dense1.bias', 'bert.encoder.v_layer.2.attention.output.dense.weight', 'bert.encoder.c_layer.4.v_intermediate.dense.weight', 'bert.encoder.c_layer.2.t_intermediate.dense.weight', 'bert.encoder.c_layer.1.biattention.query2.weight', 'bert.encoder.v_layer.0.output.dense.weight', 'bert.encoder.c_layer.0.v_output.dense.bias', 'bert.encoder.v_layer.2.output.dense.bias', 'bert.encoder.c_layer.4.biattention.key1.bias', 'bert.encoder.c_layer.5.biattention.value1.bias', 'bert.encoder.v_layer.2.attention.output.dense.bias', 'bert.encoder.c_layer.0.biOutput.dense2.bias', 'bert.encoder.v_layer.5.intermediate.dense.weight', 'bert.encoder.c_layer.4.biattention.query1.weight', 'bert.encoder.c_layer.4.v_output.LayerNorm.weight', 'bert.encoder.c_layer.3.biOutput.q_dense1.bias', 'bert.encoder.v_layer.4.output.LayerNorm.weight', 'bert.encoder.v_layer.1.intermediate.dense.bias', 'bert.encoder.c_layer.0.t_output.LayerNorm.weight', 'bert.encoder.v_layer.4.attention.self.query.bias', 'bert.encoder.c_layer.3.t_output.LayerNorm.bias', 'bert.encoder.c_layer.1.biattention.value2.weight', 'bert.encoder.v_layer.1.attention.output.dense.bias', 'bert.encoder.c_layer.5.biOutput.dense1.weight', 'bert.encoder.c_layer.5.v_output.dense.bias', 'bert.encoder.c_layer.5.biattention.key2.weight', 'bert.encoder.c_layer.3.v_intermediate.dense.weight', 'bert.encoder.v_layer.5.output.LayerNorm.bias', 'bert.encoder.v_layer.5.attention.output.dense.bias', 'bert.encoder.c_layer.2.biOutput.q_dense1.weight', 'bert.encoder.c_layer.3.t_output.dense.weight', 'bert.encoder.v_layer.2.attention.self.key.weight', 'bert.encoder.c_layer.0.v_output.dense.weight', 'bert.encoder.c_layer.5.biattention.key2.bias', 'bert.encoder.c_layer.4.t_output.dense.weight', 'bert.encoder.c_layer.5.biOutput.q_dense2.weight', 'bert.encoder.v_layer.5.attention.self.value.bias', 'bert.encoder.c_layer.2.biOutput.q_dense1.bias', 'bert.encoder.c_layer.2.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.0.t_output.LayerNorm.bias', 'bert.encoder.c_layer.0.biattention.key2.bias', 'bert.encoder.c_layer.1.biattention.value2.bias', 'bert.encoder.c_layer.1.v_output.dense.bias', 'bert.encoder.c_layer.3.biOutput.q_dense1.weight', 'bert.encoder.c_layer.3.biattention.value2.weight', 'bert.encoder.c_layer.4.biattention.query2.bias', 'bert.encoder.v_layer.1.intermediate.dense.weight', 'bert.encoder.c_layer.0.biOutput.dense1.weight', 'bert.encoder.v_layer.1.attention.self.key.weight', 'bert.encoder.v_layer.4.attention.self.key.bias', 'bert.encoder.v_layer.1.attention.self.query.bias', 'bert.encoder.c_layer.4.t_output.dense.bias', 'bert.encoder.c_layer.2.biOutput.dense2.weight', 'bert.encoder.v_layer.5.output.LayerNorm.weight', 'bert.encoder.c_layer.3.biattention.key1.bias', 'bert.encoder.c_layer.4.t_intermediate.dense.bias', 'bert.encoder.c_layer.0.biattention.query1.weight', 'bert.encoder.c_layer.4.biattention.key1.weight', 'bert.encoder.c_layer.3.biOutput.dense2.weight', 'bert.encoder.c_layer.4.biattention.value1.bias', 'bert.encoder.c_layer.5.biOutput.q_dense1.weight', 'bert.encoder.v_layer.2.attention.self.key.bias', 'bert.encoder.v_layer.3.output.LayerNorm.weight', 'bert.encoder.c_layer.5.t_output.LayerNorm.bias', 'bert.encoder.c_layer.2.biattention.query1.weight', 'bert.t_pooler.dense.weight', 'bert.encoder.c_layer.1.biOutput.q_dense2.weight', 'bert.encoder.c_layer.3.biattention.key2.weight', 'bert.encoder.c_layer.0.t_output.dense.weight', 'bert.v_pooler.dense.bias', 'bert.encoder.c_layer.0.biattention.value1.bias', 'bert.encoder.v_layer.1.attention.self.query.weight', 'bert.encoder.v_layer.4.attention.output.dense.bias', 'bert.encoder.c_layer.2.biOutput.dense2.bias', 'bert.encoder.v_layer.3.attention.self.value.bias', 'bert.encoder.c_layer.0.biOutput.q_dense2.bias', 'bert.v_embeddings.LayerNorm.bias', 'bert.encoder.c_layer.3.biOutput.LayerNorm1.bias', 'bert.encoder.v_layer.4.attention.self.key.weight', 'bert.v_embeddings.image_location_embeddings.bias', 'bert.encoder.c_layer.0.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.0.biOutput.q_dense1.bias', 'bert.encoder.c_layer.1.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.2.biattention.key2.bias', 'bert.encoder.c_layer.1.v_output.LayerNorm.bias', 'bert.encoder.c_layer.5.biattention.query2.weight', 'bert.encoder.c_layer.1.biattention.key1.weight', 'bert.encoder.c_layer.1.biOutput.dense2.weight', 'bert.encoder.c_layer.3.v_output.dense.weight', 'bert.encoder.c_layer.0.t_output.dense.bias', 'bert.encoder.c_layer.3.biattention.key2.bias', 'bert.encoder.v_layer.2.attention.self.query.weight', 'bert.encoder.v_layer.0.output.LayerNorm.weight', 'bert.encoder.v_layer.4.output.dense.bias', 'bert.encoder.v_layer.1.output.dense.bias', 'bert.encoder.c_layer.2.biattention.value2.weight', 'bert.encoder.v_layer.1.output.LayerNorm.weight', 'bert.encoder.v_layer.1.output.LayerNorm.bias', 'bert.encoder.c_layer.1.v_output.LayerNorm.weight', 'bert.encoder.c_layer.5.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.1.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.5.biattention.value1.weight', 'bert.encoder.c_layer.2.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.3.t_output.LayerNorm.weight', 'bert.v_embeddings.LayerNorm.weight', 'bert.encoder.c_layer.0.v_intermediate.dense.weight', 'bert.encoder.c_layer.1.biOutput.q_dense2.bias', 'bert.encoder.c_layer.3.biattention.value1.bias', 'bert.encoder.c_layer.4.biattention.query2.weight', 'bert.encoder.v_layer.3.attention.self.value.weight', 'bert.encoder.c_layer.5.v_intermediate.dense.weight', 'bert.encoder.v_layer.2.intermediate.dense.weight', 'bert.encoder.c_layer.0.biattention.query2.weight', 'bert.encoder.v_layer.3.output.LayerNorm.bias', 'bert.v_embeddings.image_location_embeddings.weight', 'bert.encoder.c_layer.1.v_output.dense.weight', 'bert.encoder.v_layer.3.attention.self.key.bias', 'bert.encoder.c_layer.3.biOutput.dense1.weight', 'bert.encoder.c_layer.3.t_intermediate.dense.weight', 'bert.encoder.c_layer.5.t_output.LayerNorm.weight', 'bert.encoder.c_layer.3.biattention.query2.bias', 'bert.v_pooler.dense.weight', 'bert.encoder.c_layer.1.biattention.value1.bias', 'bert.encoder.c_layer.4.biattention.key2.weight', 'bert.encoder.v_layer.5.output.dense.weight', 'bert.encoder.c_layer.1.biOutput.q_dense1.weight', 'bert.encoder.c_layer.1.biOutput.dense1.bias', 'bert.encoder.v_layer.3.output.dense.weight', 'bert.encoder.c_layer.4.v_output.LayerNorm.bias', 'bert.encoder.c_layer.5.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.5.biOutput.dense2.weight', 'bert.encoder.v_layer.3.attention.output.dense.bias', 'bert.encoder.c_layer.5.v_output.dense.weight', 'bert.encoder.c_layer.4.biOutput.q_dense2.bias', 'bert.encoder.v_layer.2.output.LayerNorm.weight', 'bert.encoder.c_layer.2.biattention.key1.bias', 'bert.encoder.v_layer.5.attention.output.dense.weight', 'bert.encoder.c_layer.2.biattention.query2.weight', 'bert.encoder.v_layer.4.attention.output.LayerNorm.weight', 'bert.encoder.c_layer.2.v_output.LayerNorm.bias', 'bert.encoder.c_layer.4.v_output.dense.bias', 'bert.encoder.c_layer.2.biattention.key2.weight', 'bert.encoder.v_layer.2.attention.self.value.weight', 'bert.encoder.c_layer.5.biOutput.LayerNorm2.weight', 'bert.encoder.v_layer.1.attention.output.dense.weight', 'bert.encoder.c_layer.5.biattention.key1.weight', 'bert.encoder.c_layer.5.t_output.dense.bias', 'bert.encoder.c_layer.3.v_intermediate.dense.bias', 'bert.encoder.v_layer.1.attention.output.LayerNorm.bias', 'bert.encoder.c_layer.4.biOutput.dense1.weight', 'bert.encoder.c_layer.4.biOutput.q_dense1.bias', 'bert.v_embeddings.image_embeddings.weight', 'bert.encoder.c_layer.2.t_output.LayerNorm.weight', 'bert.encoder.c_layer.1.biattention.key2.bias', 'bert.encoder.c_layer.1.biOutput.dense1.weight', 'bert.encoder.c_layer.3.v_output.LayerNorm.weight', 'bert.encoder.v_layer.0.attention.self.value.weight', 'bert.encoder.v_layer.0.attention.output.dense.weight', 'bert.encoder.c_layer.5.biattention.query1.weight', 'bert.encoder.c_layer.5.biattention.value2.bias', 'bert.encoder.v_layer.1.attention.self.key.bias', 'bert.encoder.c_layer.2.biOutput.dense1.weight', 'bert.encoder.v_layer.4.output.LayerNorm.bias', 'bert.encoder.c_layer.0.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.4.biattention.value2.weight', 'bert.encoder.v_layer.4.intermediate.dense.weight', 'bert.encoder.c_layer.2.v_output.LayerNorm.weight', 'bert.encoder.c_layer.3.t_intermediate.dense.bias', 'bert.encoder.c_layer.2.biOutput.q_dense2.bias', 'bert.encoder.c_layer.2.v_intermediate.dense.weight', 'bert.encoder.v_layer.1.attention.self.value.bias', 'bert.encoder.c_layer.0.biOutput.q_dense2.weight', 'bert.encoder.c_layer.3.t_output.dense.bias', 'bert.encoder.v_layer.0.attention.self.query.bias', 'bert.encoder.c_layer.5.v_output.LayerNorm.bias', 'bert.encoder.c_layer.4.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.4.t_output.LayerNorm.weight', 'bert.encoder.c_layer.0.biattention.query2.bias', 'bert.encoder.v_layer.3.intermediate.dense.weight', 'bert.encoder.c_layer.3.biOutput.q_dense2.bias', 'bert.encoder.c_layer.1.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.4.biattention.value2.bias', 'bert.encoder.c_layer.1.biattention.query1.bias', 'bert.encoder.v_layer.1.output.dense.weight', 'bert.encoder.c_layer.0.v_intermediate.dense.bias', 'bert.encoder.v_layer.2.attention.output.LayerNorm.bias', 'bert.encoder.c_layer.1.v_intermediate.dense.bias', 'bert.encoder.c_layer.2.biattention.value1.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2021-11-30T18:24:04 | mmf.trainers.mmf_trainer: \u001b[0mLoading optimizer\n",
      "\u001b[32m2021-11-30T18:24:04 | mmf.trainers.mmf_trainer: \u001b[0mLoading metrics\n",
      "\u001b[32m2021-11-30T18:24:04 | mmf.utils.checkpoint: \u001b[0mLoading checkpoint\n",
      "[ Downloading: https://dl.fbaipublicfiles.com/mmf/data/models/vilbert/vilbert.pretrained.cc_original.tar.gz to /home/jupyter/.cache/torch/mmf/data/models/vilbert.pretrained.cc.original/vilbert.pretrained.cc_original.tar.gz ]\n",
      "Downloading vilbert.pretrained.cc_original.tar.gz: 100%|| 918M/918M [00:26<00:0\n",
      "[ Starting checksum for vilbert.pretrained.cc_original.tar.gz]\n",
      "[ Checksum successful for vilbert.pretrained.cc_original.tar.gz]\n",
      "Unpacking vilbert.pretrained.cc_original.tar.gz\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-11-30T18:24:44 | mmf: \u001b[0mKey data_parallel is not present in registry, returning default value of None\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-11-30T18:24:44 | mmf: \u001b[0mKey distributed is not present in registry, returning default value of None\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-11-30T18:24:44 | mmf: \u001b[0mKey data_parallel is not present in registry, returning default value of None\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-11-30T18:24:44 | mmf: \u001b[0mKey distributed is not present in registry, returning default value of None\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.word_embeddings.weight from model.bert.embeddings.word_embeddings.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.position_embeddings.weight from model.bert.embeddings.position_embeddings.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.token_type_embeddings.weight from model.bert.embeddings.token_type_embeddings.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.LayerNorm.weight from model.bert.embeddings.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.LayerNorm.bias from model.bert.embeddings.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.v_embeddings.image_embeddings.weight from model.bert.v_embeddings.image_embeddings.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.v_embeddings.image_embeddings.bias from model.bert.v_embeddings.image_embeddings.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.v_embeddings.image_location_embeddings.weight from model.bert.v_embeddings.image_location_embeddings.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.v_embeddings.image_location_embeddings.bias from model.bert.v_embeddings.image_location_embeddings.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.v_embeddings.LayerNorm.weight from model.bert.v_embeddings.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.v_embeddings.LayerNorm.bias from model.bert.v_embeddings.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.query.weight from model.bert.encoder.layer.0.attention.self.query.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.query.bias from model.bert.encoder.layer.0.attention.self.query.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.key.weight from model.bert.encoder.layer.0.attention.self.key.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.key.bias from model.bert.encoder.layer.0.attention.self.key.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.value.weight from model.bert.encoder.layer.0.attention.self.value.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.value.bias from model.bert.encoder.layer.0.attention.self.value.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.output.dense.weight from model.bert.encoder.layer.0.attention.output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.output.dense.bias from model.bert.encoder.layer.0.attention.output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.output.LayerNorm.weight from model.bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.output.LayerNorm.bias from model.bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.intermediate.dense.weight from model.bert.encoder.layer.0.intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.intermediate.dense.bias from model.bert.encoder.layer.0.intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.output.dense.weight from model.bert.encoder.layer.0.output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.output.dense.bias from model.bert.encoder.layer.0.output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.output.LayerNorm.weight from model.bert.encoder.layer.0.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.output.LayerNorm.bias from model.bert.encoder.layer.0.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.query.weight from model.bert.encoder.layer.1.attention.self.query.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.query.bias from model.bert.encoder.layer.1.attention.self.query.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.key.weight from model.bert.encoder.layer.1.attention.self.key.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.key.bias from model.bert.encoder.layer.1.attention.self.key.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.value.weight from model.bert.encoder.layer.1.attention.self.value.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.value.bias from model.bert.encoder.layer.1.attention.self.value.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.output.dense.weight from model.bert.encoder.layer.1.attention.output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.output.dense.bias from model.bert.encoder.layer.1.attention.output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.output.LayerNorm.weight from model.bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.output.LayerNorm.bias from model.bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.intermediate.dense.weight from model.bert.encoder.layer.1.intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.intermediate.dense.bias from model.bert.encoder.layer.1.intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.output.dense.weight from model.bert.encoder.layer.1.output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.output.dense.bias from model.bert.encoder.layer.1.output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.output.LayerNorm.weight from model.bert.encoder.layer.1.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.output.LayerNorm.bias from model.bert.encoder.layer.1.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.query.weight from model.bert.encoder.layer.2.attention.self.query.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.query.bias from model.bert.encoder.layer.2.attention.self.query.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.key.weight from model.bert.encoder.layer.2.attention.self.key.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.key.bias from model.bert.encoder.layer.2.attention.self.key.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.value.weight from model.bert.encoder.layer.2.attention.self.value.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.value.bias from model.bert.encoder.layer.2.attention.self.value.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.output.dense.weight from model.bert.encoder.layer.2.attention.output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.output.dense.bias from model.bert.encoder.layer.2.attention.output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.output.LayerNorm.weight from model.bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.output.LayerNorm.bias from model.bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.intermediate.dense.weight from model.bert.encoder.layer.2.intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.intermediate.dense.bias from model.bert.encoder.layer.2.intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.output.dense.weight from model.bert.encoder.layer.2.output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.output.dense.bias from model.bert.encoder.layer.2.output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.output.LayerNorm.weight from model.bert.encoder.layer.2.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.output.LayerNorm.bias from model.bert.encoder.layer.2.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.query.weight from model.bert.encoder.layer.3.attention.self.query.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.query.bias from model.bert.encoder.layer.3.attention.self.query.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.key.weight from model.bert.encoder.layer.3.attention.self.key.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.key.bias from model.bert.encoder.layer.3.attention.self.key.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.value.weight from model.bert.encoder.layer.3.attention.self.value.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.value.bias from model.bert.encoder.layer.3.attention.self.value.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.output.dense.weight from model.bert.encoder.layer.3.attention.output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.output.dense.bias from model.bert.encoder.layer.3.attention.output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.output.LayerNorm.weight from model.bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.output.LayerNorm.bias from model.bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.intermediate.dense.weight from model.bert.encoder.layer.3.intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.intermediate.dense.bias from model.bert.encoder.layer.3.intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.output.dense.weight from model.bert.encoder.layer.3.output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.output.dense.bias from model.bert.encoder.layer.3.output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.output.LayerNorm.weight from model.bert.encoder.layer.3.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.output.LayerNorm.bias from model.bert.encoder.layer.3.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.query.weight from model.bert.encoder.layer.4.attention.self.query.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.query.bias from model.bert.encoder.layer.4.attention.self.query.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.key.weight from model.bert.encoder.layer.4.attention.self.key.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.key.bias from model.bert.encoder.layer.4.attention.self.key.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.value.weight from model.bert.encoder.layer.4.attention.self.value.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.value.bias from model.bert.encoder.layer.4.attention.self.value.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.output.dense.weight from model.bert.encoder.layer.4.attention.output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.output.dense.bias from model.bert.encoder.layer.4.attention.output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.output.LayerNorm.weight from model.bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.output.LayerNorm.bias from model.bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.intermediate.dense.weight from model.bert.encoder.layer.4.intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.intermediate.dense.bias from model.bert.encoder.layer.4.intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.output.dense.weight from model.bert.encoder.layer.4.output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.output.dense.bias from model.bert.encoder.layer.4.output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.output.LayerNorm.weight from model.bert.encoder.layer.4.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.output.LayerNorm.bias from model.bert.encoder.layer.4.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.query.weight from model.bert.encoder.layer.5.attention.self.query.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.query.bias from model.bert.encoder.layer.5.attention.self.query.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.key.weight from model.bert.encoder.layer.5.attention.self.key.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.key.bias from model.bert.encoder.layer.5.attention.self.key.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.value.weight from model.bert.encoder.layer.5.attention.self.value.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.value.bias from model.bert.encoder.layer.5.attention.self.value.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.output.dense.weight from model.bert.encoder.layer.5.attention.output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.output.dense.bias from model.bert.encoder.layer.5.attention.output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.output.LayerNorm.weight from model.bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.output.LayerNorm.bias from model.bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.intermediate.dense.weight from model.bert.encoder.layer.5.intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.intermediate.dense.bias from model.bert.encoder.layer.5.intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.output.dense.weight from model.bert.encoder.layer.5.output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.output.dense.bias from model.bert.encoder.layer.5.output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.output.LayerNorm.weight from model.bert.encoder.layer.5.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.output.LayerNorm.bias from model.bert.encoder.layer.5.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.query.weight from model.bert.encoder.layer.6.attention.self.query.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.query.bias from model.bert.encoder.layer.6.attention.self.query.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.key.weight from model.bert.encoder.layer.6.attention.self.key.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.key.bias from model.bert.encoder.layer.6.attention.self.key.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.value.weight from model.bert.encoder.layer.6.attention.self.value.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.value.bias from model.bert.encoder.layer.6.attention.self.value.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.output.dense.weight from model.bert.encoder.layer.6.attention.output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.output.dense.bias from model.bert.encoder.layer.6.attention.output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.output.LayerNorm.weight from model.bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.output.LayerNorm.bias from model.bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.intermediate.dense.weight from model.bert.encoder.layer.6.intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.intermediate.dense.bias from model.bert.encoder.layer.6.intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.output.dense.weight from model.bert.encoder.layer.6.output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.output.dense.bias from model.bert.encoder.layer.6.output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.output.LayerNorm.weight from model.bert.encoder.layer.6.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.output.LayerNorm.bias from model.bert.encoder.layer.6.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.query.weight from model.bert.encoder.layer.7.attention.self.query.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.query.bias from model.bert.encoder.layer.7.attention.self.query.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.key.weight from model.bert.encoder.layer.7.attention.self.key.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.key.bias from model.bert.encoder.layer.7.attention.self.key.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.value.weight from model.bert.encoder.layer.7.attention.self.value.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.value.bias from model.bert.encoder.layer.7.attention.self.value.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.output.dense.weight from model.bert.encoder.layer.7.attention.output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.output.dense.bias from model.bert.encoder.layer.7.attention.output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.output.LayerNorm.weight from model.bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.output.LayerNorm.bias from model.bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.intermediate.dense.weight from model.bert.encoder.layer.7.intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.intermediate.dense.bias from model.bert.encoder.layer.7.intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.output.dense.weight from model.bert.encoder.layer.7.output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.output.dense.bias from model.bert.encoder.layer.7.output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.output.LayerNorm.weight from model.bert.encoder.layer.7.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.output.LayerNorm.bias from model.bert.encoder.layer.7.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.query.weight from model.bert.encoder.layer.8.attention.self.query.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.query.bias from model.bert.encoder.layer.8.attention.self.query.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.key.weight from model.bert.encoder.layer.8.attention.self.key.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.key.bias from model.bert.encoder.layer.8.attention.self.key.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.value.weight from model.bert.encoder.layer.8.attention.self.value.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.value.bias from model.bert.encoder.layer.8.attention.self.value.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.output.dense.weight from model.bert.encoder.layer.8.attention.output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.output.dense.bias from model.bert.encoder.layer.8.attention.output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.output.LayerNorm.weight from model.bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.output.LayerNorm.bias from model.bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.intermediate.dense.weight from model.bert.encoder.layer.8.intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.intermediate.dense.bias from model.bert.encoder.layer.8.intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.output.dense.weight from model.bert.encoder.layer.8.output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.output.dense.bias from model.bert.encoder.layer.8.output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.output.LayerNorm.weight from model.bert.encoder.layer.8.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.output.LayerNorm.bias from model.bert.encoder.layer.8.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.query.weight from model.bert.encoder.layer.9.attention.self.query.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.query.bias from model.bert.encoder.layer.9.attention.self.query.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.key.weight from model.bert.encoder.layer.9.attention.self.key.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.key.bias from model.bert.encoder.layer.9.attention.self.key.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.value.weight from model.bert.encoder.layer.9.attention.self.value.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.value.bias from model.bert.encoder.layer.9.attention.self.value.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.output.dense.weight from model.bert.encoder.layer.9.attention.output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.output.dense.bias from model.bert.encoder.layer.9.attention.output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.output.LayerNorm.weight from model.bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.output.LayerNorm.bias from model.bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.intermediate.dense.weight from model.bert.encoder.layer.9.intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.intermediate.dense.bias from model.bert.encoder.layer.9.intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.output.dense.weight from model.bert.encoder.layer.9.output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.output.dense.bias from model.bert.encoder.layer.9.output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.output.LayerNorm.weight from model.bert.encoder.layer.9.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.output.LayerNorm.bias from model.bert.encoder.layer.9.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.query.weight from model.bert.encoder.layer.10.attention.self.query.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.query.bias from model.bert.encoder.layer.10.attention.self.query.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.key.weight from model.bert.encoder.layer.10.attention.self.key.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.key.bias from model.bert.encoder.layer.10.attention.self.key.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.value.weight from model.bert.encoder.layer.10.attention.self.value.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.value.bias from model.bert.encoder.layer.10.attention.self.value.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.output.dense.weight from model.bert.encoder.layer.10.attention.output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.output.dense.bias from model.bert.encoder.layer.10.attention.output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.output.LayerNorm.weight from model.bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.output.LayerNorm.bias from model.bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.intermediate.dense.weight from model.bert.encoder.layer.10.intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.intermediate.dense.bias from model.bert.encoder.layer.10.intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.output.dense.weight from model.bert.encoder.layer.10.output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.output.dense.bias from model.bert.encoder.layer.10.output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.output.LayerNorm.weight from model.bert.encoder.layer.10.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.output.LayerNorm.bias from model.bert.encoder.layer.10.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.query.weight from model.bert.encoder.layer.11.attention.self.query.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.query.bias from model.bert.encoder.layer.11.attention.self.query.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.key.weight from model.bert.encoder.layer.11.attention.self.key.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.key.bias from model.bert.encoder.layer.11.attention.self.key.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.value.weight from model.bert.encoder.layer.11.attention.self.value.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.value.bias from model.bert.encoder.layer.11.attention.self.value.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.output.dense.weight from model.bert.encoder.layer.11.attention.output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.output.dense.bias from model.bert.encoder.layer.11.attention.output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.output.LayerNorm.weight from model.bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.output.LayerNorm.bias from model.bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.intermediate.dense.weight from model.bert.encoder.layer.11.intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.intermediate.dense.bias from model.bert.encoder.layer.11.intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.output.dense.weight from model.bert.encoder.layer.11.output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.output.dense.bias from model.bert.encoder.layer.11.output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.output.LayerNorm.weight from model.bert.encoder.layer.11.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.output.LayerNorm.bias from model.bert.encoder.layer.11.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.0.attention.self.query.weight from model.bert.encoder.v_layer.0.attention.self.query.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.0.attention.self.query.bias from model.bert.encoder.v_layer.0.attention.self.query.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.0.attention.self.key.weight from model.bert.encoder.v_layer.0.attention.self.key.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.0.attention.self.key.bias from model.bert.encoder.v_layer.0.attention.self.key.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.0.attention.self.value.weight from model.bert.encoder.v_layer.0.attention.self.value.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.0.attention.self.value.bias from model.bert.encoder.v_layer.0.attention.self.value.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.0.attention.output.dense.weight from model.bert.encoder.v_layer.0.attention.output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.0.attention.output.dense.bias from model.bert.encoder.v_layer.0.attention.output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.0.attention.output.LayerNorm.weight from model.bert.encoder.v_layer.0.attention.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.0.attention.output.LayerNorm.bias from model.bert.encoder.v_layer.0.attention.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.0.intermediate.dense.weight from model.bert.encoder.v_layer.0.intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.0.intermediate.dense.bias from model.bert.encoder.v_layer.0.intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.0.output.dense.weight from model.bert.encoder.v_layer.0.output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.0.output.dense.bias from model.bert.encoder.v_layer.0.output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.0.output.LayerNorm.weight from model.bert.encoder.v_layer.0.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.0.output.LayerNorm.bias from model.bert.encoder.v_layer.0.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.1.attention.self.query.weight from model.bert.encoder.v_layer.1.attention.self.query.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.1.attention.self.query.bias from model.bert.encoder.v_layer.1.attention.self.query.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.1.attention.self.key.weight from model.bert.encoder.v_layer.1.attention.self.key.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.1.attention.self.key.bias from model.bert.encoder.v_layer.1.attention.self.key.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.1.attention.self.value.weight from model.bert.encoder.v_layer.1.attention.self.value.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.1.attention.self.value.bias from model.bert.encoder.v_layer.1.attention.self.value.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.1.attention.output.dense.weight from model.bert.encoder.v_layer.1.attention.output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.1.attention.output.dense.bias from model.bert.encoder.v_layer.1.attention.output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.1.attention.output.LayerNorm.weight from model.bert.encoder.v_layer.1.attention.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.1.attention.output.LayerNorm.bias from model.bert.encoder.v_layer.1.attention.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.1.intermediate.dense.weight from model.bert.encoder.v_layer.1.intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.1.intermediate.dense.bias from model.bert.encoder.v_layer.1.intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.1.output.dense.weight from model.bert.encoder.v_layer.1.output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.1.output.dense.bias from model.bert.encoder.v_layer.1.output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.1.output.LayerNorm.weight from model.bert.encoder.v_layer.1.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.1.output.LayerNorm.bias from model.bert.encoder.v_layer.1.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.2.attention.self.query.weight from model.bert.encoder.v_layer.2.attention.self.query.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.2.attention.self.query.bias from model.bert.encoder.v_layer.2.attention.self.query.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.2.attention.self.key.weight from model.bert.encoder.v_layer.2.attention.self.key.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.2.attention.self.key.bias from model.bert.encoder.v_layer.2.attention.self.key.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.2.attention.self.value.weight from model.bert.encoder.v_layer.2.attention.self.value.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.2.attention.self.value.bias from model.bert.encoder.v_layer.2.attention.self.value.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.2.attention.output.dense.weight from model.bert.encoder.v_layer.2.attention.output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.2.attention.output.dense.bias from model.bert.encoder.v_layer.2.attention.output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.2.attention.output.LayerNorm.weight from model.bert.encoder.v_layer.2.attention.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.2.attention.output.LayerNorm.bias from model.bert.encoder.v_layer.2.attention.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.2.intermediate.dense.weight from model.bert.encoder.v_layer.2.intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.2.intermediate.dense.bias from model.bert.encoder.v_layer.2.intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.2.output.dense.weight from model.bert.encoder.v_layer.2.output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.2.output.dense.bias from model.bert.encoder.v_layer.2.output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.2.output.LayerNorm.weight from model.bert.encoder.v_layer.2.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.2.output.LayerNorm.bias from model.bert.encoder.v_layer.2.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.3.attention.self.query.weight from model.bert.encoder.v_layer.3.attention.self.query.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.3.attention.self.query.bias from model.bert.encoder.v_layer.3.attention.self.query.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.3.attention.self.key.weight from model.bert.encoder.v_layer.3.attention.self.key.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.3.attention.self.key.bias from model.bert.encoder.v_layer.3.attention.self.key.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.3.attention.self.value.weight from model.bert.encoder.v_layer.3.attention.self.value.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.3.attention.self.value.bias from model.bert.encoder.v_layer.3.attention.self.value.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.3.attention.output.dense.weight from model.bert.encoder.v_layer.3.attention.output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.3.attention.output.dense.bias from model.bert.encoder.v_layer.3.attention.output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.3.attention.output.LayerNorm.weight from model.bert.encoder.v_layer.3.attention.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.3.attention.output.LayerNorm.bias from model.bert.encoder.v_layer.3.attention.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.3.intermediate.dense.weight from model.bert.encoder.v_layer.3.intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.3.intermediate.dense.bias from model.bert.encoder.v_layer.3.intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.3.output.dense.weight from model.bert.encoder.v_layer.3.output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.3.output.dense.bias from model.bert.encoder.v_layer.3.output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.3.output.LayerNorm.weight from model.bert.encoder.v_layer.3.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.3.output.LayerNorm.bias from model.bert.encoder.v_layer.3.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.4.attention.self.query.weight from model.bert.encoder.v_layer.4.attention.self.query.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.4.attention.self.query.bias from model.bert.encoder.v_layer.4.attention.self.query.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.4.attention.self.key.weight from model.bert.encoder.v_layer.4.attention.self.key.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.4.attention.self.key.bias from model.bert.encoder.v_layer.4.attention.self.key.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.4.attention.self.value.weight from model.bert.encoder.v_layer.4.attention.self.value.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.4.attention.self.value.bias from model.bert.encoder.v_layer.4.attention.self.value.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.4.attention.output.dense.weight from model.bert.encoder.v_layer.4.attention.output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.4.attention.output.dense.bias from model.bert.encoder.v_layer.4.attention.output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.4.attention.output.LayerNorm.weight from model.bert.encoder.v_layer.4.attention.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.4.attention.output.LayerNorm.bias from model.bert.encoder.v_layer.4.attention.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.4.intermediate.dense.weight from model.bert.encoder.v_layer.4.intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.4.intermediate.dense.bias from model.bert.encoder.v_layer.4.intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.4.output.dense.weight from model.bert.encoder.v_layer.4.output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.4.output.dense.bias from model.bert.encoder.v_layer.4.output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.4.output.LayerNorm.weight from model.bert.encoder.v_layer.4.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.4.output.LayerNorm.bias from model.bert.encoder.v_layer.4.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.5.attention.self.query.weight from model.bert.encoder.v_layer.5.attention.self.query.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.5.attention.self.query.bias from model.bert.encoder.v_layer.5.attention.self.query.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.5.attention.self.key.weight from model.bert.encoder.v_layer.5.attention.self.key.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.5.attention.self.key.bias from model.bert.encoder.v_layer.5.attention.self.key.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.5.attention.self.value.weight from model.bert.encoder.v_layer.5.attention.self.value.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.5.attention.self.value.bias from model.bert.encoder.v_layer.5.attention.self.value.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.5.attention.output.dense.weight from model.bert.encoder.v_layer.5.attention.output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.5.attention.output.dense.bias from model.bert.encoder.v_layer.5.attention.output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.5.attention.output.LayerNorm.weight from model.bert.encoder.v_layer.5.attention.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.5.attention.output.LayerNorm.bias from model.bert.encoder.v_layer.5.attention.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.5.intermediate.dense.weight from model.bert.encoder.v_layer.5.intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.5.intermediate.dense.bias from model.bert.encoder.v_layer.5.intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.5.output.dense.weight from model.bert.encoder.v_layer.5.output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.5.output.dense.bias from model.bert.encoder.v_layer.5.output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.5.output.LayerNorm.weight from model.bert.encoder.v_layer.5.output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.v_layer.5.output.LayerNorm.bias from model.bert.encoder.v_layer.5.output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.0.biattention.query1.weight from model.bert.encoder.c_layer.0.biattention.query1.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.0.biattention.query1.bias from model.bert.encoder.c_layer.0.biattention.query1.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.0.biattention.key1.weight from model.bert.encoder.c_layer.0.biattention.key1.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.0.biattention.key1.bias from model.bert.encoder.c_layer.0.biattention.key1.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.0.biattention.value1.weight from model.bert.encoder.c_layer.0.biattention.value1.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.0.biattention.value1.bias from model.bert.encoder.c_layer.0.biattention.value1.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.0.biattention.query2.weight from model.bert.encoder.c_layer.0.biattention.query2.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.0.biattention.query2.bias from model.bert.encoder.c_layer.0.biattention.query2.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.0.biattention.key2.weight from model.bert.encoder.c_layer.0.biattention.key2.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.0.biattention.key2.bias from model.bert.encoder.c_layer.0.biattention.key2.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.0.biattention.value2.weight from model.bert.encoder.c_layer.0.biattention.value2.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.0.biattention.value2.bias from model.bert.encoder.c_layer.0.biattention.value2.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.0.biOutput.dense1.weight from model.bert.encoder.c_layer.0.biOutput.dense1.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.0.biOutput.dense1.bias from model.bert.encoder.c_layer.0.biOutput.dense1.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.0.biOutput.LayerNorm1.weight from model.bert.encoder.c_layer.0.biOutput.LayerNorm1.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.0.biOutput.LayerNorm1.bias from model.bert.encoder.c_layer.0.biOutput.LayerNorm1.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.0.biOutput.q_dense1.weight from model.bert.encoder.c_layer.0.biOutput.q_dense1.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.0.biOutput.q_dense1.bias from model.bert.encoder.c_layer.0.biOutput.q_dense1.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.0.biOutput.dense2.weight from model.bert.encoder.c_layer.0.biOutput.dense2.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.0.biOutput.dense2.bias from model.bert.encoder.c_layer.0.biOutput.dense2.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.0.biOutput.LayerNorm2.weight from model.bert.encoder.c_layer.0.biOutput.LayerNorm2.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.0.biOutput.LayerNorm2.bias from model.bert.encoder.c_layer.0.biOutput.LayerNorm2.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.0.biOutput.q_dense2.weight from model.bert.encoder.c_layer.0.biOutput.q_dense2.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.0.biOutput.q_dense2.bias from model.bert.encoder.c_layer.0.biOutput.q_dense2.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.0.v_intermediate.dense.weight from model.bert.encoder.c_layer.0.v_intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.0.v_intermediate.dense.bias from model.bert.encoder.c_layer.0.v_intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.0.v_output.dense.weight from model.bert.encoder.c_layer.0.v_output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.0.v_output.dense.bias from model.bert.encoder.c_layer.0.v_output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.0.v_output.LayerNorm.weight from model.bert.encoder.c_layer.0.v_output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.0.v_output.LayerNorm.bias from model.bert.encoder.c_layer.0.v_output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.0.t_intermediate.dense.weight from model.bert.encoder.c_layer.0.t_intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.0.t_intermediate.dense.bias from model.bert.encoder.c_layer.0.t_intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.0.t_output.dense.weight from model.bert.encoder.c_layer.0.t_output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.0.t_output.dense.bias from model.bert.encoder.c_layer.0.t_output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.0.t_output.LayerNorm.weight from model.bert.encoder.c_layer.0.t_output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.0.t_output.LayerNorm.bias from model.bert.encoder.c_layer.0.t_output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.1.biattention.query1.weight from model.bert.encoder.c_layer.1.biattention.query1.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.1.biattention.query1.bias from model.bert.encoder.c_layer.1.biattention.query1.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.1.biattention.key1.weight from model.bert.encoder.c_layer.1.biattention.key1.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.1.biattention.key1.bias from model.bert.encoder.c_layer.1.biattention.key1.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.1.biattention.value1.weight from model.bert.encoder.c_layer.1.biattention.value1.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.1.biattention.value1.bias from model.bert.encoder.c_layer.1.biattention.value1.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.1.biattention.query2.weight from model.bert.encoder.c_layer.1.biattention.query2.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.1.biattention.query2.bias from model.bert.encoder.c_layer.1.biattention.query2.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.1.biattention.key2.weight from model.bert.encoder.c_layer.1.biattention.key2.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.1.biattention.key2.bias from model.bert.encoder.c_layer.1.biattention.key2.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.1.biattention.value2.weight from model.bert.encoder.c_layer.1.biattention.value2.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.1.biattention.value2.bias from model.bert.encoder.c_layer.1.biattention.value2.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.1.biOutput.dense1.weight from model.bert.encoder.c_layer.1.biOutput.dense1.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.1.biOutput.dense1.bias from model.bert.encoder.c_layer.1.biOutput.dense1.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.1.biOutput.LayerNorm1.weight from model.bert.encoder.c_layer.1.biOutput.LayerNorm1.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.1.biOutput.LayerNorm1.bias from model.bert.encoder.c_layer.1.biOutput.LayerNorm1.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.1.biOutput.q_dense1.weight from model.bert.encoder.c_layer.1.biOutput.q_dense1.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.1.biOutput.q_dense1.bias from model.bert.encoder.c_layer.1.biOutput.q_dense1.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.1.biOutput.dense2.weight from model.bert.encoder.c_layer.1.biOutput.dense2.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.1.biOutput.dense2.bias from model.bert.encoder.c_layer.1.biOutput.dense2.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.1.biOutput.LayerNorm2.weight from model.bert.encoder.c_layer.1.biOutput.LayerNorm2.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.1.biOutput.LayerNorm2.bias from model.bert.encoder.c_layer.1.biOutput.LayerNorm2.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.1.biOutput.q_dense2.weight from model.bert.encoder.c_layer.1.biOutput.q_dense2.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.1.biOutput.q_dense2.bias from model.bert.encoder.c_layer.1.biOutput.q_dense2.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.1.v_intermediate.dense.weight from model.bert.encoder.c_layer.1.v_intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.1.v_intermediate.dense.bias from model.bert.encoder.c_layer.1.v_intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.1.v_output.dense.weight from model.bert.encoder.c_layer.1.v_output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.1.v_output.dense.bias from model.bert.encoder.c_layer.1.v_output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.1.v_output.LayerNorm.weight from model.bert.encoder.c_layer.1.v_output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.1.v_output.LayerNorm.bias from model.bert.encoder.c_layer.1.v_output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.1.t_intermediate.dense.weight from model.bert.encoder.c_layer.1.t_intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.1.t_intermediate.dense.bias from model.bert.encoder.c_layer.1.t_intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.1.t_output.dense.weight from model.bert.encoder.c_layer.1.t_output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.1.t_output.dense.bias from model.bert.encoder.c_layer.1.t_output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.1.t_output.LayerNorm.weight from model.bert.encoder.c_layer.1.t_output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.1.t_output.LayerNorm.bias from model.bert.encoder.c_layer.1.t_output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.2.biattention.query1.weight from model.bert.encoder.c_layer.2.biattention.query1.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.2.biattention.query1.bias from model.bert.encoder.c_layer.2.biattention.query1.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.2.biattention.key1.weight from model.bert.encoder.c_layer.2.biattention.key1.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.2.biattention.key1.bias from model.bert.encoder.c_layer.2.biattention.key1.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.2.biattention.value1.weight from model.bert.encoder.c_layer.2.biattention.value1.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.2.biattention.value1.bias from model.bert.encoder.c_layer.2.biattention.value1.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.2.biattention.query2.weight from model.bert.encoder.c_layer.2.biattention.query2.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.2.biattention.query2.bias from model.bert.encoder.c_layer.2.biattention.query2.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.2.biattention.key2.weight from model.bert.encoder.c_layer.2.biattention.key2.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.2.biattention.key2.bias from model.bert.encoder.c_layer.2.biattention.key2.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.2.biattention.value2.weight from model.bert.encoder.c_layer.2.biattention.value2.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.2.biattention.value2.bias from model.bert.encoder.c_layer.2.biattention.value2.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.2.biOutput.dense1.weight from model.bert.encoder.c_layer.2.biOutput.dense1.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.2.biOutput.dense1.bias from model.bert.encoder.c_layer.2.biOutput.dense1.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.2.biOutput.LayerNorm1.weight from model.bert.encoder.c_layer.2.biOutput.LayerNorm1.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.2.biOutput.LayerNorm1.bias from model.bert.encoder.c_layer.2.biOutput.LayerNorm1.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.2.biOutput.q_dense1.weight from model.bert.encoder.c_layer.2.biOutput.q_dense1.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.2.biOutput.q_dense1.bias from model.bert.encoder.c_layer.2.biOutput.q_dense1.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.2.biOutput.dense2.weight from model.bert.encoder.c_layer.2.biOutput.dense2.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.2.biOutput.dense2.bias from model.bert.encoder.c_layer.2.biOutput.dense2.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.2.biOutput.LayerNorm2.weight from model.bert.encoder.c_layer.2.biOutput.LayerNorm2.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.2.biOutput.LayerNorm2.bias from model.bert.encoder.c_layer.2.biOutput.LayerNorm2.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.2.biOutput.q_dense2.weight from model.bert.encoder.c_layer.2.biOutput.q_dense2.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.2.biOutput.q_dense2.bias from model.bert.encoder.c_layer.2.biOutput.q_dense2.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.2.v_intermediate.dense.weight from model.bert.encoder.c_layer.2.v_intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.2.v_intermediate.dense.bias from model.bert.encoder.c_layer.2.v_intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.2.v_output.dense.weight from model.bert.encoder.c_layer.2.v_output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.2.v_output.dense.bias from model.bert.encoder.c_layer.2.v_output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.2.v_output.LayerNorm.weight from model.bert.encoder.c_layer.2.v_output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.2.v_output.LayerNorm.bias from model.bert.encoder.c_layer.2.v_output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.2.t_intermediate.dense.weight from model.bert.encoder.c_layer.2.t_intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.2.t_intermediate.dense.bias from model.bert.encoder.c_layer.2.t_intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.2.t_output.dense.weight from model.bert.encoder.c_layer.2.t_output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.2.t_output.dense.bias from model.bert.encoder.c_layer.2.t_output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.2.t_output.LayerNorm.weight from model.bert.encoder.c_layer.2.t_output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.2.t_output.LayerNorm.bias from model.bert.encoder.c_layer.2.t_output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.3.biattention.query1.weight from model.bert.encoder.c_layer.3.biattention.query1.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.3.biattention.query1.bias from model.bert.encoder.c_layer.3.biattention.query1.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.3.biattention.key1.weight from model.bert.encoder.c_layer.3.biattention.key1.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.3.biattention.key1.bias from model.bert.encoder.c_layer.3.biattention.key1.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.3.biattention.value1.weight from model.bert.encoder.c_layer.3.biattention.value1.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.3.biattention.value1.bias from model.bert.encoder.c_layer.3.biattention.value1.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.3.biattention.query2.weight from model.bert.encoder.c_layer.3.biattention.query2.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.3.biattention.query2.bias from model.bert.encoder.c_layer.3.biattention.query2.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.3.biattention.key2.weight from model.bert.encoder.c_layer.3.biattention.key2.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.3.biattention.key2.bias from model.bert.encoder.c_layer.3.biattention.key2.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.3.biattention.value2.weight from model.bert.encoder.c_layer.3.biattention.value2.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.3.biattention.value2.bias from model.bert.encoder.c_layer.3.biattention.value2.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.3.biOutput.dense1.weight from model.bert.encoder.c_layer.3.biOutput.dense1.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.3.biOutput.dense1.bias from model.bert.encoder.c_layer.3.biOutput.dense1.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.3.biOutput.LayerNorm1.weight from model.bert.encoder.c_layer.3.biOutput.LayerNorm1.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.3.biOutput.LayerNorm1.bias from model.bert.encoder.c_layer.3.biOutput.LayerNorm1.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.3.biOutput.q_dense1.weight from model.bert.encoder.c_layer.3.biOutput.q_dense1.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.3.biOutput.q_dense1.bias from model.bert.encoder.c_layer.3.biOutput.q_dense1.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.3.biOutput.dense2.weight from model.bert.encoder.c_layer.3.biOutput.dense2.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.3.biOutput.dense2.bias from model.bert.encoder.c_layer.3.biOutput.dense2.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.3.biOutput.LayerNorm2.weight from model.bert.encoder.c_layer.3.biOutput.LayerNorm2.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.3.biOutput.LayerNorm2.bias from model.bert.encoder.c_layer.3.biOutput.LayerNorm2.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.3.biOutput.q_dense2.weight from model.bert.encoder.c_layer.3.biOutput.q_dense2.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.3.biOutput.q_dense2.bias from model.bert.encoder.c_layer.3.biOutput.q_dense2.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.3.v_intermediate.dense.weight from model.bert.encoder.c_layer.3.v_intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.3.v_intermediate.dense.bias from model.bert.encoder.c_layer.3.v_intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.3.v_output.dense.weight from model.bert.encoder.c_layer.3.v_output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.3.v_output.dense.bias from model.bert.encoder.c_layer.3.v_output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.3.v_output.LayerNorm.weight from model.bert.encoder.c_layer.3.v_output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.3.v_output.LayerNorm.bias from model.bert.encoder.c_layer.3.v_output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.3.t_intermediate.dense.weight from model.bert.encoder.c_layer.3.t_intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.3.t_intermediate.dense.bias from model.bert.encoder.c_layer.3.t_intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.3.t_output.dense.weight from model.bert.encoder.c_layer.3.t_output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.3.t_output.dense.bias from model.bert.encoder.c_layer.3.t_output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.3.t_output.LayerNorm.weight from model.bert.encoder.c_layer.3.t_output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.3.t_output.LayerNorm.bias from model.bert.encoder.c_layer.3.t_output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.4.biattention.query1.weight from model.bert.encoder.c_layer.4.biattention.query1.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.4.biattention.query1.bias from model.bert.encoder.c_layer.4.biattention.query1.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.4.biattention.key1.weight from model.bert.encoder.c_layer.4.biattention.key1.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.4.biattention.key1.bias from model.bert.encoder.c_layer.4.biattention.key1.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.4.biattention.value1.weight from model.bert.encoder.c_layer.4.biattention.value1.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.4.biattention.value1.bias from model.bert.encoder.c_layer.4.biattention.value1.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.4.biattention.query2.weight from model.bert.encoder.c_layer.4.biattention.query2.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.4.biattention.query2.bias from model.bert.encoder.c_layer.4.biattention.query2.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.4.biattention.key2.weight from model.bert.encoder.c_layer.4.biattention.key2.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.4.biattention.key2.bias from model.bert.encoder.c_layer.4.biattention.key2.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.4.biattention.value2.weight from model.bert.encoder.c_layer.4.biattention.value2.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.4.biattention.value2.bias from model.bert.encoder.c_layer.4.biattention.value2.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.4.biOutput.dense1.weight from model.bert.encoder.c_layer.4.biOutput.dense1.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.4.biOutput.dense1.bias from model.bert.encoder.c_layer.4.biOutput.dense1.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.4.biOutput.LayerNorm1.weight from model.bert.encoder.c_layer.4.biOutput.LayerNorm1.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.4.biOutput.LayerNorm1.bias from model.bert.encoder.c_layer.4.biOutput.LayerNorm1.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.4.biOutput.q_dense1.weight from model.bert.encoder.c_layer.4.biOutput.q_dense1.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.4.biOutput.q_dense1.bias from model.bert.encoder.c_layer.4.biOutput.q_dense1.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.4.biOutput.dense2.weight from model.bert.encoder.c_layer.4.biOutput.dense2.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.4.biOutput.dense2.bias from model.bert.encoder.c_layer.4.biOutput.dense2.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.4.biOutput.LayerNorm2.weight from model.bert.encoder.c_layer.4.biOutput.LayerNorm2.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.4.biOutput.LayerNorm2.bias from model.bert.encoder.c_layer.4.biOutput.LayerNorm2.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.4.biOutput.q_dense2.weight from model.bert.encoder.c_layer.4.biOutput.q_dense2.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.4.biOutput.q_dense2.bias from model.bert.encoder.c_layer.4.biOutput.q_dense2.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.4.v_intermediate.dense.weight from model.bert.encoder.c_layer.4.v_intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.4.v_intermediate.dense.bias from model.bert.encoder.c_layer.4.v_intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.4.v_output.dense.weight from model.bert.encoder.c_layer.4.v_output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.4.v_output.dense.bias from model.bert.encoder.c_layer.4.v_output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.4.v_output.LayerNorm.weight from model.bert.encoder.c_layer.4.v_output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.4.v_output.LayerNorm.bias from model.bert.encoder.c_layer.4.v_output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.4.t_intermediate.dense.weight from model.bert.encoder.c_layer.4.t_intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.4.t_intermediate.dense.bias from model.bert.encoder.c_layer.4.t_intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.4.t_output.dense.weight from model.bert.encoder.c_layer.4.t_output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.4.t_output.dense.bias from model.bert.encoder.c_layer.4.t_output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.4.t_output.LayerNorm.weight from model.bert.encoder.c_layer.4.t_output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.4.t_output.LayerNorm.bias from model.bert.encoder.c_layer.4.t_output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.5.biattention.query1.weight from model.bert.encoder.c_layer.5.biattention.query1.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.5.biattention.query1.bias from model.bert.encoder.c_layer.5.biattention.query1.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.5.biattention.key1.weight from model.bert.encoder.c_layer.5.biattention.key1.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.5.biattention.key1.bias from model.bert.encoder.c_layer.5.biattention.key1.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.5.biattention.value1.weight from model.bert.encoder.c_layer.5.biattention.value1.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.5.biattention.value1.bias from model.bert.encoder.c_layer.5.biattention.value1.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.5.biattention.query2.weight from model.bert.encoder.c_layer.5.biattention.query2.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.5.biattention.query2.bias from model.bert.encoder.c_layer.5.biattention.query2.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.5.biattention.key2.weight from model.bert.encoder.c_layer.5.biattention.key2.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.5.biattention.key2.bias from model.bert.encoder.c_layer.5.biattention.key2.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.5.biattention.value2.weight from model.bert.encoder.c_layer.5.biattention.value2.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.5.biattention.value2.bias from model.bert.encoder.c_layer.5.biattention.value2.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.5.biOutput.dense1.weight from model.bert.encoder.c_layer.5.biOutput.dense1.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.5.biOutput.dense1.bias from model.bert.encoder.c_layer.5.biOutput.dense1.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.5.biOutput.LayerNorm1.weight from model.bert.encoder.c_layer.5.biOutput.LayerNorm1.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.5.biOutput.LayerNorm1.bias from model.bert.encoder.c_layer.5.biOutput.LayerNorm1.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.5.biOutput.q_dense1.weight from model.bert.encoder.c_layer.5.biOutput.q_dense1.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.5.biOutput.q_dense1.bias from model.bert.encoder.c_layer.5.biOutput.q_dense1.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.5.biOutput.dense2.weight from model.bert.encoder.c_layer.5.biOutput.dense2.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.5.biOutput.dense2.bias from model.bert.encoder.c_layer.5.biOutput.dense2.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.5.biOutput.LayerNorm2.weight from model.bert.encoder.c_layer.5.biOutput.LayerNorm2.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.5.biOutput.LayerNorm2.bias from model.bert.encoder.c_layer.5.biOutput.LayerNorm2.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.5.biOutput.q_dense2.weight from model.bert.encoder.c_layer.5.biOutput.q_dense2.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.5.biOutput.q_dense2.bias from model.bert.encoder.c_layer.5.biOutput.q_dense2.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.5.v_intermediate.dense.weight from model.bert.encoder.c_layer.5.v_intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.5.v_intermediate.dense.bias from model.bert.encoder.c_layer.5.v_intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.5.v_output.dense.weight from model.bert.encoder.c_layer.5.v_output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.5.v_output.dense.bias from model.bert.encoder.c_layer.5.v_output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.5.v_output.LayerNorm.weight from model.bert.encoder.c_layer.5.v_output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.5.v_output.LayerNorm.bias from model.bert.encoder.c_layer.5.v_output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.5.t_intermediate.dense.weight from model.bert.encoder.c_layer.5.t_intermediate.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.5.t_intermediate.dense.bias from model.bert.encoder.c_layer.5.t_intermediate.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.5.t_output.dense.weight from model.bert.encoder.c_layer.5.t_output.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.5.t_output.dense.bias from model.bert.encoder.c_layer.5.t_output.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.5.t_output.LayerNorm.weight from model.bert.encoder.c_layer.5.t_output.LayerNorm.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.c_layer.5.t_output.LayerNorm.bias from model.bert.encoder.c_layer.5.t_output.LayerNorm.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.t_pooler.dense.weight from model.bert.t_pooler.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.t_pooler.dense.bias from model.bert.t_pooler.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.v_pooler.dense.weight from model.bert.v_pooler.dense.weight\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.v_pooler.dense.bias from model.bert.v_pooler.dense.bias\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mPretrained model loaded\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCheckpoint loaded.\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCurrent num updates: 0\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCurrent iteration: 0\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.utils.checkpoint: \u001b[0mCurrent epoch: 0\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.trainers.mmf_trainer: \u001b[0m===== Model =====\n",
      "\u001b[32m2021-11-30T18:24:44 | mmf.trainers.mmf_trainer: \u001b[0mViLBERT(\n",
      "  (model): ViLBERTForClassification(\n",
      "    (bert): ViLBERTBase(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (v_embeddings): BertImageFeatureEmbeddings(\n",
      "        (image_embeddings): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "        (image_location_embeddings): Linear(in_features=5, out_features=1024, bias=True)\n",
      "        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (v_layer): ModuleList(\n",
      "          (0): BertImageLayer(\n",
      "            (attention): BertImageAttention(\n",
      "              (self): BertImageSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertImageSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertImageIntermediate(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (output): BertImageOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertImageLayer(\n",
      "            (attention): BertImageAttention(\n",
      "              (self): BertImageSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertImageSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertImageIntermediate(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (output): BertImageOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertImageLayer(\n",
      "            (attention): BertImageAttention(\n",
      "              (self): BertImageSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertImageSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertImageIntermediate(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (output): BertImageOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertImageLayer(\n",
      "            (attention): BertImageAttention(\n",
      "              (self): BertImageSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertImageSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertImageIntermediate(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (output): BertImageOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertImageLayer(\n",
      "            (attention): BertImageAttention(\n",
      "              (self): BertImageSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertImageSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertImageIntermediate(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (output): BertImageOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertImageLayer(\n",
      "            (attention): BertImageAttention(\n",
      "              (self): BertImageSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertImageSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertImageIntermediate(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (output): BertImageOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (c_layer): ModuleList(\n",
      "          (0): BertConnectionLayer(\n",
      "            (biattention): BertBiAttention(\n",
      "              (query1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (query2): Linear(in_features=768, out_features=1024, bias=True)\n",
      "              (key2): Linear(in_features=768, out_features=1024, bias=True)\n",
      "              (value2): Linear(in_features=768, out_features=1024, bias=True)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (biOutput): BertBiOutput(\n",
      "              (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
      "              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
      "              (q_dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (v_intermediate): BertImageIntermediate(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (v_output): BertImageOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (t_intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (t_output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertConnectionLayer(\n",
      "            (biattention): BertBiAttention(\n",
      "              (query1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (query2): Linear(in_features=768, out_features=1024, bias=True)\n",
      "              (key2): Linear(in_features=768, out_features=1024, bias=True)\n",
      "              (value2): Linear(in_features=768, out_features=1024, bias=True)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (biOutput): BertBiOutput(\n",
      "              (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
      "              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
      "              (q_dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (v_intermediate): BertImageIntermediate(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (v_output): BertImageOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (t_intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (t_output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertConnectionLayer(\n",
      "            (biattention): BertBiAttention(\n",
      "              (query1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (query2): Linear(in_features=768, out_features=1024, bias=True)\n",
      "              (key2): Linear(in_features=768, out_features=1024, bias=True)\n",
      "              (value2): Linear(in_features=768, out_features=1024, bias=True)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (biOutput): BertBiOutput(\n",
      "              (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
      "              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
      "              (q_dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (v_intermediate): BertImageIntermediate(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (v_output): BertImageOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (t_intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (t_output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertConnectionLayer(\n",
      "            (biattention): BertBiAttention(\n",
      "              (query1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (query2): Linear(in_features=768, out_features=1024, bias=True)\n",
      "              (key2): Linear(in_features=768, out_features=1024, bias=True)\n",
      "              (value2): Linear(in_features=768, out_features=1024, bias=True)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (biOutput): BertBiOutput(\n",
      "              (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
      "              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
      "              (q_dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (v_intermediate): BertImageIntermediate(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (v_output): BertImageOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (t_intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (t_output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertConnectionLayer(\n",
      "            (biattention): BertBiAttention(\n",
      "              (query1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (query2): Linear(in_features=768, out_features=1024, bias=True)\n",
      "              (key2): Linear(in_features=768, out_features=1024, bias=True)\n",
      "              (value2): Linear(in_features=768, out_features=1024, bias=True)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (biOutput): BertBiOutput(\n",
      "              (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
      "              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
      "              (q_dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (v_intermediate): BertImageIntermediate(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (v_output): BertImageOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (t_intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (t_output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertConnectionLayer(\n",
      "            (biattention): BertBiAttention(\n",
      "              (query1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (query2): Linear(in_features=768, out_features=1024, bias=True)\n",
      "              (key2): Linear(in_features=768, out_features=1024, bias=True)\n",
      "              (value2): Linear(in_features=768, out_features=1024, bias=True)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (biOutput): BertBiOutput(\n",
      "              (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
      "              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
      "              (q_dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (v_intermediate): BertImageIntermediate(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (v_output): BertImageOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (t_intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (t_output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (t_pooler): BertTextPooler(\n",
      "        (dense): Linear(in_features=768, out_features=1024, bias=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (v_pooler): BertImagePooler(\n",
      "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (classifier): Sequential(\n",
      "      (0): BertPredictionHeadTransform(\n",
      "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "      )\n",
      "      (1): Linear(in_features=1024, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (losses): Losses(\n",
      "    (losses): ModuleList(\n",
      "      (0): MMFLoss(\n",
      "        (loss_criterion): CrossEntropyLoss(\n",
      "          (loss_fn): CrossEntropyLoss()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m2021-11-30T18:24:45 | mmf.utils.general: \u001b[0mTotal Parameters: 247780354. Trained Parameters: 247780354\n",
      "\u001b[32m2021-11-30T18:24:45 | mmf.trainers.core.training_loop: \u001b[0mStarting training...\n",
      "\u001b[32m2021-11-30T18:26:14 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 50/3000, train/hateful_memes/cross_entropy: 0.7333, train/hateful_memes/cross_entropy/avg: 0.7333, train/total_loss: 0.7333, train/total_loss/avg: 0.7333, max mem: 7256.0, experiment: run, epoch: 1, num_updates: 50, iterations: 50, max_updates: 3000, lr: 0., ups: 0.56, time: 01m 29s 606ms, time_since_start: 02m 10s 150ms, eta: 01h 34m 06s 264ms\n",
      "\u001b[32m2021-11-30T18:27:39 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 100/3000, train/hateful_memes/cross_entropy: 0.7333, train/hateful_memes/cross_entropy/avg: 0.7740, train/total_loss: 0.7333, train/total_loss/avg: 0.7740, max mem: 7256.0, experiment: run, epoch: 1, num_updates: 100, iterations: 100, max_updates: 3000, lr: 0., ups: 0.60, time: 01m 24s 518ms, time_since_start: 03m 34s 669ms, eta: 01h 27m 15s 441ms\n",
      "\u001b[32m2021-11-30T18:29:03 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 150/3000, train/hateful_memes/cross_entropy: 0.7506, train/hateful_memes/cross_entropy/avg: 0.7662, train/total_loss: 0.7506, train/total_loss/avg: 0.7662, max mem: 7256.0, experiment: run, epoch: 1, num_updates: 150, iterations: 150, max_updates: 3000, lr: 0., ups: 0.60, time: 01m 24s 593ms, time_since_start: 04m 59s 263ms, eta: 01h 25m 49s 742ms\n"
     ]
    }
   ],
   "source": [
    "!mmf_run config=projects/hateful_memes/configs/vilbert/from_cc.yaml \\\n",
    "  model=vilbert \\\n",
    "  dataset=hateful_memes \\\n",
    "  training.log_interval=50 \\\n",
    "  training.max_updates=3000 \\\n",
    "  training.batch_size=16 \\\n",
    "  training.evaluation_interval=500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c18ccb-1fdf-4a87-89b1-bc2f6608bcae",
   "metadata": {},
   "source": [
    "mmf_run config=projects/hateful_memes/configs/vilbert/from_cc.yaml model=vilbert dataset=hateful_memes training.log_interval=50 training.max_updates=3000 training.batch_size=16 training.evaluation_interval=500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbc4ea1-5722-4435-aa46-aef63dd5066c",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13e3831e-8a8c-4c7d-b619-0d055e30589a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/save/hateful_memes_visual_bert_27100065/best.ckpt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "home='/home/jupyter'\n",
    "os.chdir(home)\n",
    "# where checkpoint is\n",
    "ckpt_dir = os.path.join(home, \"save/hateful_memes_visual_bert_27100065/best.ckpt\")\n",
    "print(ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c94937-98e0-44db-a3ff-5983e61f9083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual Bert Coco\n",
    "# validation\n",
    "!mmf_predict config=projects/hateful_memes/configs/visual_bert/from_coco.yaml model=visual_bert dataset=hateful_memes \\\n",
    "run_type=val checkpoint.resume_file=/home/jupyter/save/hateful_memes_visual_bert_27100065/best.ckpt checkpoint.resume_pretrained=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23626e17-7635-4f6a-87b4-d38c3a6adfe7",
   "metadata": {},
   "source": [
    "mmf_predict config=projects/hateful_memes/configs/visual_bert/from_coco.yaml model=visual_bert dataset=hateful_memes run_type=val checkpoint.resume_file=/home/jupyter/save/hateful_memes_visual_bert_27100065/best.ckpt checkpoint.resume_pretrained=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1067ffe7-795c-4789-a890-dd7d9e6a4e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VilBert CC\n",
    "# validation & test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1517fb-19d0-4a80-9f2e-61d72bd03e97",
   "metadata": {},
   "source": [
    "mmf_predict config=projects/hateful_memes/configs/vilbert/from_cc.yaml model=vilbert dataset=hateful_memes run_type=val checkpoint.resume_file=/home/jupyter/save/hateful_memes_vilbert_36477203/best.ckpt checkpoint.resume_pretrained=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff7be1e-96fa-40e7-9cec-3a624647c310",
   "metadata": {},
   "source": [
    "mmf_predict config=projects/hateful_memes/configs/vilbert/from_cc.yaml model=vilbert dataset=hateful_memes run_type=test checkpoint.resume_file=/home/jupyter/save/hateful_memes_vilbert_36477203/best.ckpt checkpoint.resume_pretrained=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d666d7-5847-4dee-9157-27df4b1bb987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualbert COCO prediction on dev seen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a581dd-fae6-43ff-8fb2-61dd76cf31fd",
   "metadata": {},
   "source": [
    "mmf_predict config=projects/hateful_memes/configs/visual_bert/from_coco.yaml model=visual_bert dataset=hateful_memes run_type=val checkpoint.resume_file=/home/jupyter/save/models/visualbert_coco/best.ckpt checkpoint.resume_pretrained=False dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev_seen.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6101d12-363c-41fe-8789-8ba573b1116d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualbert COCO prediction on test seen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33b258b-962a-4e20-8043-e9eec572febf",
   "metadata": {},
   "source": [
    "mmf_predict config=projects/hateful_memes/configs/visual_bert/from_coco.yaml model=visual_bert dataset=hateful_memes run_type=test checkpoint.resume_file=/home/jupyter/save/models/visualbert_coco/best.ckpt checkpoint.resume_pretrained=False dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test_seen.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b06d94-72d7-4894-b014-a945370585ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vilbert cc prediction on dev seen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ac18dd-ba5f-4b87-9d9a-a309494dd638",
   "metadata": {},
   "source": [
    "mmf_predict config=projects/hateful_memes/configs/vilbert/from_cc.yaml model=vilbert dataset=hateful_memes run_type=val checkpoint.resume_file=/home/jupyter/save/models/vilbert_cc/best.ckpt checkpoint.resume_pretrained=False\n",
    "dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev_seen.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c310d0b-2083-46c1-8a90-9004049fb370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vilbert cc prediction on test seen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa3f8ac-c899-4585-a82e-910000311a84",
   "metadata": {},
   "source": [
    "mmf_predict config=projects/hateful_memes/configs/vilbert/from_cc.yaml model=vilbert dataset=hateful_memes run_type=test checkpoint.resume_file=/home/jupyter/save/models/vilbert_cc/best.ckpt checkpoint.resume_pretrained=False dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test_seen.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f212e11-3584-4150-814e-0ae0ab2e0c7f",
   "metadata": {},
   "source": [
    "## Memotion Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8997e0ce-4033-4cf4-9eaa-11c038c6382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "home='/home/jupyter'\n",
    "os.chdir(home)\n",
    "# !git clone https://github.com/rizavelioglu/hateful_memes-hate_detectron.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdfdfd75-d95c-438f-80f3-f1d3fe75ca6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12141\n"
     ]
    }
   ],
   "source": [
    "# Check how many images we have in total\n",
    "!sudo ls /home/jupyter/.cache/torch/mmf/data/datasets/hateful_memes/defaults/images/img/ | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31d5e508-711d-4b18-9e76-d2dffb174634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read the .jsonl file and get the img column\n",
    "labeled_memo_samples = pd.read_json(os.path.join(home, \"hateful_memes-hate_detectron/utils/label_memotion.jsonl\"), lines=True)['img']\n",
    "# parse the img entries and get the image names\n",
    "labeled_memo_samples = [i.split('/')[1] for i in list(labeled_memo_samples)]\n",
    "\n",
    "# Before proceeding, need to change the file ownership to jupyter if it's not using:\n",
    "# sudo chown -R 1001:1002 .\n",
    "img_dir = os.path.join(home, f\"memotion_dataset_7k/images/\")\n",
    "\n",
    "for img in labeled_memo_samples:\n",
    "    try:\n",
    "        os.rename(f\"{img_dir+img}\", f\"{home}/.cache/torch/mmf/data/datasets/hateful_memes/defaults/images/img/{img}\")\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d62fc42-28db-47d0-b6e3-ed59cc48e5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12469\n"
     ]
    }
   ],
   "source": [
    "# Check how many images we have in total\n",
    "!sudo ls /home/jupyter/.cache/torch/mmf/data/datasets/hateful_memes/defaults/images/img/ | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e6a6f39-898b-417d-8ea9-1f20aa54601b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python $home/hateful_memes-hate_detectron/utils/concat_memotion-hm.py --home $home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba21d9d-ff05-4144-8697-c4c93abe77a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on train_v10.jsonl\n",
    "!mmf_run config=projects/hateful_memes/configs/visual_bert/from_coco.yaml \\\n",
    "  model=visual_bert \\\n",
    "  dataset=hateful_memes \\\n",
    "  training.log_interval=50 \\\n",
    "  training.max_updates=3000 \\\n",
    "  training.batch_size=16 \\\n",
    "  training.evaluation_interval=500\n",
    "  dataset_config.hateful_memes.annotations.train[0]=/home/jupyter/train_v10.jsonl \\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7473bd9e-9af7-4d3c-bd18-f44c5d96254d",
   "metadata": {},
   "source": [
    "mmf_run config=projects/hateful_memes/configs/visual_bert/from_coco.yaml model=visual_bert dataset=hateful_memes training.log_interval=50 training.max_updates=3000 training.batch_size=16 training.evaluation_interval=500 dataset_config.hateful_memes.annotations.train[0]=/home/jupyter/train_v10.jsonl\n",
    "\n",
    "\n",
    "\n",
    "KeyError: b'image_2077'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d4f4ef-43c2-4f92-b096-d5c1b7f6b351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e45d43-3629-47ec-9dfd-ed07df24d7e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8e9d9c6-204c-4aa7-824a-a5642a280ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'vqa-maskrcnn-benchmark'...\n",
      "warning: redirecting to https://gitlab.com/vedanuj/vqa-maskrcnn-benchmark.git/\n",
      "remote: Enumerating objects: 764, done.\u001b[K\n",
      "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
      "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
      "remote: Total 764 (delta 10), reused 30 (delta 8), pack-reused 729\u001b[K\n",
      "Receiving objects: 100% (764/764), 3.78 MiB | 27.46 MiB/s, done.\n",
      "Resolving deltas: 100% (401/401), done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(home)\n",
    "!git clone https://gitlab.com/vedanuj/vqa-maskrcnn-benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41291078-97c1-41e6-942f-bd99499c1654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ninja\n",
      "  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
      "     || 108 kB 7.0 MB/s            \n",
      "\u001b[?25hCollecting yacs\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: cython in /opt/conda/lib/python3.7/site-packages (0.29.24)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (3.3.4)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from yacs) (6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (1.19.5)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (3.0.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (8.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib) (1.16.0)\n",
      "Installing collected packages: yacs, ninja\n",
      "Successfully installed ninja-1.10.2.3 yacs-0.1.8\n"
     ]
    }
   ],
   "source": [
    "!pip install ninja yacs cython matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ed65800-5300-4c99-b1f0-e845f2c3fb0b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib.linux-x86_64-3.7\n",
      "creating build/lib.linux-x86_64-3.7/maskrcnn_benchmark\n",
      "copying maskrcnn_benchmark/__init__.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark\n",
      "creating build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling\n",
      "copying maskrcnn_benchmark/modeling/registry.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling\n",
      "copying maskrcnn_benchmark/modeling/__init__.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling\n",
      "copying maskrcnn_benchmark/modeling/poolers.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling\n",
      "copying maskrcnn_benchmark/modeling/matcher.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling\n",
      "copying maskrcnn_benchmark/modeling/utils.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling\n",
      "copying maskrcnn_benchmark/modeling/balanced_positive_negative_sampler.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling\n",
      "copying maskrcnn_benchmark/modeling/box_coder.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling\n",
      "creating build/lib.linux-x86_64-3.7/maskrcnn_benchmark/data\n",
      "copying maskrcnn_benchmark/data/__init__.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/data\n",
      "copying maskrcnn_benchmark/data/build.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/data\n",
      "copying maskrcnn_benchmark/data/collate_batch.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/data\n",
      "creating build/lib.linux-x86_64-3.7/maskrcnn_benchmark/config\n",
      "copying maskrcnn_benchmark/config/defaults.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/config\n",
      "copying maskrcnn_benchmark/config/__init__.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/config\n",
      "copying maskrcnn_benchmark/config/paths_catalog.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/config\n",
      "creating build/lib.linux-x86_64-3.7/maskrcnn_benchmark/engine\n",
      "copying maskrcnn_benchmark/engine/trainer.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/engine\n",
      "copying maskrcnn_benchmark/engine/__init__.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/engine\n",
      "copying maskrcnn_benchmark/engine/inference.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/engine\n",
      "creating build/lib.linux-x86_64-3.7/maskrcnn_benchmark/solver\n",
      "copying maskrcnn_benchmark/solver/lr_scheduler.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/solver\n",
      "copying maskrcnn_benchmark/solver/__init__.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/solver\n",
      "copying maskrcnn_benchmark/solver/build.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/solver\n",
      "creating build/lib.linux-x86_64-3.7/maskrcnn_benchmark/layers\n",
      "copying maskrcnn_benchmark/layers/roi_align.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/layers\n",
      "copying maskrcnn_benchmark/layers/nms.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/layers\n",
      "copying maskrcnn_benchmark/layers/smooth_l1_loss.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/layers\n",
      "copying maskrcnn_benchmark/layers/roi_pool.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/layers\n",
      "copying maskrcnn_benchmark/layers/__init__.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/layers\n",
      "copying maskrcnn_benchmark/layers/_utils.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/layers\n",
      "copying maskrcnn_benchmark/layers/batch_norm.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/layers\n",
      "copying maskrcnn_benchmark/layers/misc.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/layers\n",
      "creating build/lib.linux-x86_64-3.7/maskrcnn_benchmark/structures\n",
      "copying maskrcnn_benchmark/structures/segmentation_mask.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/structures\n",
      "copying maskrcnn_benchmark/structures/bounding_box.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/structures\n",
      "copying maskrcnn_benchmark/structures/__init__.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/structures\n",
      "copying maskrcnn_benchmark/structures/boxlist_ops.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/structures\n",
      "copying maskrcnn_benchmark/structures/image_list.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/structures\n",
      "creating build/lib.linux-x86_64-3.7/maskrcnn_benchmark/utils\n",
      "copying maskrcnn_benchmark/utils/miscellaneous.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/utils\n",
      "copying maskrcnn_benchmark/utils/registry.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/utils\n",
      "copying maskrcnn_benchmark/utils/checkpoint.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/utils\n",
      "copying maskrcnn_benchmark/utils/metric_logger.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/utils\n",
      "copying maskrcnn_benchmark/utils/c2_model_loading.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/utils\n",
      "copying maskrcnn_benchmark/utils/env.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/utils\n",
      "copying maskrcnn_benchmark/utils/model_zoo.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/utils\n",
      "copying maskrcnn_benchmark/utils/__init__.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/utils\n",
      "copying maskrcnn_benchmark/utils/logger.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/utils\n",
      "copying maskrcnn_benchmark/utils/comm.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/utils\n",
      "copying maskrcnn_benchmark/utils/collect_env.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/utils\n",
      "copying maskrcnn_benchmark/utils/model_serialization.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/utils\n",
      "copying maskrcnn_benchmark/utils/imports.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/utils\n",
      "creating build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling/roi_heads\n",
      "copying maskrcnn_benchmark/modeling/roi_heads/roi_heads.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling/roi_heads\n",
      "copying maskrcnn_benchmark/modeling/roi_heads/__init__.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling/roi_heads\n",
      "creating build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling/rpn\n",
      "copying maskrcnn_benchmark/modeling/rpn/rpn.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling/rpn\n",
      "copying maskrcnn_benchmark/modeling/rpn/anchor_generator.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling/rpn\n",
      "copying maskrcnn_benchmark/modeling/rpn/loss.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling/rpn\n",
      "copying maskrcnn_benchmark/modeling/rpn/__init__.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling/rpn\n",
      "copying maskrcnn_benchmark/modeling/rpn/inference.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling/rpn\n",
      "creating build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling/backbone\n",
      "copying maskrcnn_benchmark/modeling/backbone/fpn.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling/backbone\n",
      "copying maskrcnn_benchmark/modeling/backbone/backbone.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling/backbone\n",
      "copying maskrcnn_benchmark/modeling/backbone/__init__.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling/backbone\n",
      "copying maskrcnn_benchmark/modeling/backbone/resnet.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling/backbone\n",
      "creating build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling/detector\n",
      "copying maskrcnn_benchmark/modeling/detector/__init__.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling/detector\n",
      "copying maskrcnn_benchmark/modeling/detector/generalized_rcnn.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling/detector\n",
      "copying maskrcnn_benchmark/modeling/detector/detectors.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling/detector\n",
      "creating build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling/roi_heads/mask_head\n",
      "copying maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_feature_extractors.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling/roi_heads/mask_head\n",
      "copying maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_predictors.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling/roi_heads/mask_head\n",
      "copying maskrcnn_benchmark/modeling/roi_heads/mask_head/loss.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling/roi_heads/mask_head\n",
      "copying maskrcnn_benchmark/modeling/roi_heads/mask_head/__init__.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling/roi_heads/mask_head\n",
      "copying maskrcnn_benchmark/modeling/roi_heads/mask_head/mask_head.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling/roi_heads/mask_head\n",
      "copying maskrcnn_benchmark/modeling/roi_heads/mask_head/inference.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling/roi_heads/mask_head\n",
      "creating build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling/roi_heads/box_head\n",
      "copying maskrcnn_benchmark/modeling/roi_heads/box_head/box_head.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling/roi_heads/box_head\n",
      "copying maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_predictors.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling/roi_heads/box_head\n",
      "copying maskrcnn_benchmark/modeling/roi_heads/box_head/loss.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling/roi_heads/box_head\n",
      "copying maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_feature_extractors.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling/roi_heads/box_head\n",
      "copying maskrcnn_benchmark/modeling/roi_heads/box_head/__init__.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling/roi_heads/box_head\n",
      "copying maskrcnn_benchmark/modeling/roi_heads/box_head/inference.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/modeling/roi_heads/box_head\n",
      "creating build/lib.linux-x86_64-3.7/maskrcnn_benchmark/data/datasets\n",
      "copying maskrcnn_benchmark/data/datasets/coco.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/data/datasets\n",
      "copying maskrcnn_benchmark/data/datasets/__init__.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/data/datasets\n",
      "copying maskrcnn_benchmark/data/datasets/voc.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/data/datasets\n",
      "copying maskrcnn_benchmark/data/datasets/list_dataset.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/data/datasets\n",
      "copying maskrcnn_benchmark/data/datasets/concat_dataset.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/data/datasets\n",
      "creating build/lib.linux-x86_64-3.7/maskrcnn_benchmark/data/transforms\n",
      "copying maskrcnn_benchmark/data/transforms/__init__.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/data/transforms\n",
      "copying maskrcnn_benchmark/data/transforms/build.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/data/transforms\n",
      "copying maskrcnn_benchmark/data/transforms/transforms.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/data/transforms\n",
      "creating build/lib.linux-x86_64-3.7/maskrcnn_benchmark/data/samplers\n",
      "copying maskrcnn_benchmark/data/samplers/grouped_batch_sampler.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/data/samplers\n",
      "copying maskrcnn_benchmark/data/samplers/__init__.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/data/samplers\n",
      "copying maskrcnn_benchmark/data/samplers/distributed.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/data/samplers\n",
      "copying maskrcnn_benchmark/data/samplers/iteration_based_batch_sampler.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/data/samplers\n",
      "creating build/lib.linux-x86_64-3.7/maskrcnn_benchmark/data/datasets/evaluation\n",
      "copying maskrcnn_benchmark/data/datasets/evaluation/__init__.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/data/datasets/evaluation\n",
      "creating build/lib.linux-x86_64-3.7/maskrcnn_benchmark/data/datasets/evaluation/coco\n",
      "copying maskrcnn_benchmark/data/datasets/evaluation/coco/coco_eval.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/data/datasets/evaluation/coco\n",
      "copying maskrcnn_benchmark/data/datasets/evaluation/coco/__init__.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/data/datasets/evaluation/coco\n",
      "creating build/lib.linux-x86_64-3.7/maskrcnn_benchmark/data/datasets/evaluation/voc\n",
      "copying maskrcnn_benchmark/data/datasets/evaluation/voc/voc_eval.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/data/datasets/evaluation/voc\n",
      "copying maskrcnn_benchmark/data/datasets/evaluation/voc/__init__.py -> build/lib.linux-x86_64-3.7/maskrcnn_benchmark/data/datasets/evaluation/voc\n",
      "running build_ext\n",
      "building 'maskrcnn_benchmark._C' extension\n",
      "creating /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7\n",
      "creating /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home\n",
      "creating /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home/jupyter\n",
      "creating /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home/jupyter/vqa-maskrcnn-benchmark\n",
      "creating /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark\n",
      "creating /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc\n",
      "creating /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu\n",
      "creating /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda\n",
      "Emitting ninja build file /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/build.ninja...\n",
      "Compiling objects...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "[1/6] /usr/local/cuda/bin/nvcc  -DWITH_CUDA -I/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/ROIAlign_cuda.cu -o /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/ROIAlign_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "[2/6] /usr/local/cuda/bin/nvcc  -DWITH_CUDA -I/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/ROIPool_cuda.cu -o /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/ROIPool_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "[3/6] /usr/local/cuda/bin/nvcc  -DWITH_CUDA -I/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/nms.cu -o /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/nms.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "[4/6] c++ -MMD -MF /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.o.d -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DWITH_CUDA -I/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp -o /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "cc1plus: warning: command line option -Wstrict-prototypes is valid for C/ObjC but not for C++\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Parallel.h:140,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:13,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/ParallelOpenMP.h:87: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
      " #pragma omp parallel for if ((end - begin) >= grain_size)\n",
      " \n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp: In function at::Tensor ROIAlign_forward_cpu(const at::Tensor&, const at::Tensor&, float, int, int, int):\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:227:26: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_ASSERTM(!input.type().is_cuda(), \"input must be a CPU tensor\");\n",
      "                          ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:230:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
      "                                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:250:34: note: in expansion of macro C10_UNLIKELY\n",
      " #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
      "                                  ^~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:302:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:588:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n",
      "     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
      "                                ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:227:3: note: in expansion of macro AT_ASSERTM\n",
      "   AT_ASSERTM(!input.type().is_cuda(), \"input must be a CPU tensor\");\n",
      "   ^~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:228:25: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_ASSERTM(!rois.type().is_cuda(), \"rois must be a CPU tensor\");\n",
      "                         ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:230:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
      "                                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:250:34: note: in expansion of macro C10_UNLIKELY\n",
      " #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
      "                                  ^~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:302:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:588:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n",
      "     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
      "                                ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:228:3: note: in expansion of macro AT_ASSERTM\n",
      "   AT_ASSERTM(!rois.type().is_cuda(), \"rois must be a CPU tensor\");\n",
      "   ^~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:13,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp: In lambda function:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:242:41: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_DISPATCH_FLOATING_TYPES(input.type(), \"ROIAlign_forward\", [&] {\n",
      "                                         ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:207:28: note: in definition of macro AT_DISPATCH_FLOATING_TYPES\n",
      "     const auto& the_type = TYPE;                                            \\\n",
      "                            ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:13,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:209:56: warning: c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&) is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
      "     at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n",
      "                                                        ^\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:242:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES\n",
      "   AT_DISPATCH_FLOATING_TYPES(input.type(), \"ROIAlign_forward\", [&] {\n",
      "   ^~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:121:23: note: declared here\n",
      " inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
      "                       ^~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:209:56: warning: c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&) is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
      "     at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n",
      "                                                        ^\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:242:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES\n",
      "   AT_DISPATCH_FLOATING_TYPES(input.type(), \"ROIAlign_forward\", [&] {\n",
      "   ^~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:121:23: note: declared here\n",
      " inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
      "                       ^~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp: In lambda function:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:245:31: warning: T* at::Tensor::data() const [with T = double] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "          input.data<scalar_t>(),\n",
      "                               ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
      "     return __VA_ARGS__();                                                        \\\n",
      "            ^~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:212:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n",
      "       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)     \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:242:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES\n",
      "   AT_DISPATCH_FLOATING_TYPES(input.type(), \"ROIAlign_forward\", [&] {\n",
      "   ^~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:13,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:253:30: warning: T* at::Tensor::data() const [with T = double] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "          rois.data<scalar_t>(),\n",
      "                              ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
      "     return __VA_ARGS__();                                                        \\\n",
      "            ^~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:212:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n",
      "       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)     \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:242:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES\n",
      "   AT_DISPATCH_FLOATING_TYPES(input.type(), \"ROIAlign_forward\", [&] {\n",
      "   ^~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:13,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:254:32: warning: T* at::Tensor::data() const [with T = double] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "          output.data<scalar_t>());\n",
      "                                ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
      "     return __VA_ARGS__();                                                        \\\n",
      "            ^~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:212:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n",
      "       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)     \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:242:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES\n",
      "   AT_DISPATCH_FLOATING_TYPES(input.type(), \"ROIAlign_forward\", [&] {\n",
      "   ^~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:13,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp: In lambda function:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:245:31: warning: T* at::Tensor::data() const [with T = float] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "          input.data<scalar_t>(),\n",
      "                               ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
      "     return __VA_ARGS__();                                                        \\\n",
      "            ^~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:213:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n",
      "       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)       \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:242:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES\n",
      "   AT_DISPATCH_FLOATING_TYPES(input.type(), \"ROIAlign_forward\", [&] {\n",
      "   ^~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:13,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:253:30: warning: T* at::Tensor::data() const [with T = float] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "          rois.data<scalar_t>(),\n",
      "                              ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
      "     return __VA_ARGS__();                                                        \\\n",
      "            ^~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:213:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n",
      "       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)       \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:242:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES\n",
      "   AT_DISPATCH_FLOATING_TYPES(input.type(), \"ROIAlign_forward\", [&] {\n",
      "   ^~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:13,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:254:32: warning: T* at::Tensor::data() const [with T = float] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "          output.data<scalar_t>());\n",
      "                                ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
      "     return __VA_ARGS__();                                                        \\\n",
      "            ^~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:213:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n",
      "       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)       \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:242:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES\n",
      "   AT_DISPATCH_FLOATING_TYPES(input.type(), \"ROIAlign_forward\", [&] {\n",
      "   ^~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "[5/6] c++ -MMD -MF /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.o.d -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DWITH_CUDA -I/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp -o /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "cc1plus: warning: command line option -Wstrict-prototypes is valid for C/ObjC but not for C++\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Parallel.h:140,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:13,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/ParallelOpenMP.h:87: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
      " #pragma omp parallel for if ((end - begin) >= grain_size)\n",
      " \n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:13,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp: In lambda function:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:71:40: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_DISPATCH_FLOATING_TYPES(dets.type(), \"nms\", [&] {\n",
      "                                        ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:207:28: note: in definition of macro AT_DISPATCH_FLOATING_TYPES\n",
      "     const auto& the_type = TYPE;                                            \\\n",
      "                            ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:13,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:209:56: warning: c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&) is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
      "     at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n",
      "                                                        ^\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:71:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES\n",
      "   AT_DISPATCH_FLOATING_TYPES(dets.type(), \"nms\", [&] {\n",
      "   ^~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:121:23: note: declared here\n",
      " inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
      "                       ^~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:209:56: warning: c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&) is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
      "     at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n",
      "                                                        ^\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:71:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES\n",
      "   AT_DISPATCH_FLOATING_TYPES(dets.type(), \"nms\", [&] {\n",
      "   ^~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:121:23: note: declared here\n",
      " inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
      "                       ^~~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp: In instantiation of at::Tensor nms_cpu_kernel(const at::Tensor&, const at::Tensor&, float) [with scalar_t = double]:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:71:3:   required from here\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:9:24: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_ASSERTM(!dets.type().is_cuda(), \"dets must be a CPU tensor\");\n",
      "               ~~~~~~~~~^~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:230:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
      "                                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:250:34: note: in expansion of macro C10_UNLIKELY\n",
      " #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
      "                                  ^~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:302:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:588:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n",
      "     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
      "                                ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:9:3: note: in expansion of macro AT_ASSERTM\n",
      "   AT_ASSERTM(!dets.type().is_cuda(), \"dets must be a CPU tensor\");\n",
      "   ^~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:9:24: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_ASSERTM(!dets.type().is_cuda(), \"dets must be a CPU tensor\");\n",
      "               ~~~~~~~~~^~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:230:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
      "                                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:250:34: note: in expansion of macro C10_UNLIKELY\n",
      " #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
      "                                  ^~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:302:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:588:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n",
      "     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
      "                                ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:9:3: note: in expansion of macro AT_ASSERTM\n",
      "   AT_ASSERTM(!dets.type().is_cuda(), \"dets must be a CPU tensor\");\n",
      "   ^~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:10:26: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_ASSERTM(!scores.type().is_cuda(), \"scores must be a CPU tensor\");\n",
      "               ~~~~~~~~~~~^~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:230:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
      "                                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:250:34: note: in expansion of macro C10_UNLIKELY\n",
      " #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
      "                                  ^~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:302:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:588:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n",
      "     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
      "                                ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:10:3: note: in expansion of macro AT_ASSERTM\n",
      "   AT_ASSERTM(!scores.type().is_cuda(), \"scores must be a CPU tensor\");\n",
      "   ^~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:10:26: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_ASSERTM(!scores.type().is_cuda(), \"scores must be a CPU tensor\");\n",
      "               ~~~~~~~~~~~^~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:230:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
      "                                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:250:34: note: in expansion of macro C10_UNLIKELY\n",
      " #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
      "                                  ^~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:302:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:588:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n",
      "     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
      "                                ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:10:3: note: in expansion of macro AT_ASSERTM\n",
      "   AT_ASSERTM(!scores.type().is_cuda(), \"scores must be a CPU tensor\");\n",
      "   ^~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:23: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_ASSERTM(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
      "              ~~~~~~~~~^~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:230:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
      "                                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:250:34: note: in expansion of macro C10_UNLIKELY\n",
      " #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
      "                                  ^~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:302:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:588:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n",
      "     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
      "                                ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:3: note: in expansion of macro AT_ASSERTM\n",
      "   AT_ASSERTM(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
      "   ^~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:23: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_ASSERTM(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
      "              ~~~~~~~~~^~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:230:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
      "                                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:250:34: note: in expansion of macro C10_UNLIKELY\n",
      " #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
      "                                  ^~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:302:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:588:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n",
      "     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
      "                                ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:3: note: in expansion of macro AT_ASSERTM\n",
      "   AT_ASSERTM(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
      "   ^~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:40: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_ASSERTM(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
      "                             ~~~~~~~~~~~^~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:230:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
      "                                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:250:34: note: in expansion of macro C10_UNLIKELY\n",
      " #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
      "                                  ^~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:302:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:588:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n",
      "     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
      "                                ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:3: note: in expansion of macro AT_ASSERTM\n",
      "   AT_ASSERTM(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
      "   ^~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:40: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_ASSERTM(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
      "                             ~~~~~~~~~~~^~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:230:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
      "                                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:250:34: note: in expansion of macro C10_UNLIKELY\n",
      " #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
      "                                  ^~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:302:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:588:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n",
      "     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
      "                                ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:3: note: in expansion of macro AT_ASSERTM\n",
      "   AT_ASSERTM(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
      "   ^~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:29:47: warning: T* at::Tensor::data() const [with T = unsigned char] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "   auto suppressed = suppressed_t.data<uint8_t>();\n",
      "                     ~~~~~~~~~~~~~~~~~~~~~~~~~~^~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:30:37: warning: T* at::Tensor::data() const [with T = long int] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "   auto order = order_t.data<int64_t>();\n",
      "                ~~~~~~~~~~~~~~~~~~~~~^~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:31:8: warning: T* at::Tensor::data() const [with T = double] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "   auto x1 = x1_t.data<scalar_t>();\n",
      "        ^~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:32:8: warning: T* at::Tensor::data() const [with T = double] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "   auto y1 = y1_t.data<scalar_t>();\n",
      "        ^~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:33:8: warning: T* at::Tensor::data() const [with T = double] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "   auto x2 = x2_t.data<scalar_t>();\n",
      "        ^~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:34:8: warning: T* at::Tensor::data() const [with T = double] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "   auto y2 = y2_t.data<scalar_t>();\n",
      "        ^~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:35:8: warning: T* at::Tensor::data() const [with T = double] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "   auto areas = areas_t.data<scalar_t>();\n",
      "        ^~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp: In instantiation of at::Tensor nms_cpu_kernel(const at::Tensor&, const at::Tensor&, float) [with scalar_t = float]:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:71:3:   required from here\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:9:24: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_ASSERTM(!dets.type().is_cuda(), \"dets must be a CPU tensor\");\n",
      "               ~~~~~~~~~^~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:230:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
      "                                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:250:34: note: in expansion of macro C10_UNLIKELY\n",
      " #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
      "                                  ^~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:302:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:588:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n",
      "     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
      "                                ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:9:3: note: in expansion of macro AT_ASSERTM\n",
      "   AT_ASSERTM(!dets.type().is_cuda(), \"dets must be a CPU tensor\");\n",
      "   ^~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:9:24: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_ASSERTM(!dets.type().is_cuda(), \"dets must be a CPU tensor\");\n",
      "               ~~~~~~~~~^~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:230:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
      "                                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:250:34: note: in expansion of macro C10_UNLIKELY\n",
      " #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
      "                                  ^~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:302:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:588:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n",
      "     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
      "                                ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:9:3: note: in expansion of macro AT_ASSERTM\n",
      "   AT_ASSERTM(!dets.type().is_cuda(), \"dets must be a CPU tensor\");\n",
      "   ^~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:10:26: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_ASSERTM(!scores.type().is_cuda(), \"scores must be a CPU tensor\");\n",
      "               ~~~~~~~~~~~^~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:230:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
      "                                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:250:34: note: in expansion of macro C10_UNLIKELY\n",
      " #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
      "                                  ^~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:302:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:588:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n",
      "     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
      "                                ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:10:3: note: in expansion of macro AT_ASSERTM\n",
      "   AT_ASSERTM(!scores.type().is_cuda(), \"scores must be a CPU tensor\");\n",
      "   ^~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:10:26: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_ASSERTM(!scores.type().is_cuda(), \"scores must be a CPU tensor\");\n",
      "               ~~~~~~~~~~~^~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:230:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
      "                                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:250:34: note: in expansion of macro C10_UNLIKELY\n",
      " #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
      "                                  ^~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:302:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:588:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n",
      "     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
      "                                ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:10:3: note: in expansion of macro AT_ASSERTM\n",
      "   AT_ASSERTM(!scores.type().is_cuda(), \"scores must be a CPU tensor\");\n",
      "   ^~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:23: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_ASSERTM(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
      "              ~~~~~~~~~^~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:230:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
      "                                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:250:34: note: in expansion of macro C10_UNLIKELY\n",
      " #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
      "                                  ^~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:302:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:588:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n",
      "     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
      "                                ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:3: note: in expansion of macro AT_ASSERTM\n",
      "   AT_ASSERTM(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
      "   ^~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:23: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_ASSERTM(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
      "              ~~~~~~~~~^~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:230:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
      "                                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:250:34: note: in expansion of macro C10_UNLIKELY\n",
      " #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
      "                                  ^~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:302:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:588:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n",
      "     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
      "                                ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:3: note: in expansion of macro AT_ASSERTM\n",
      "   AT_ASSERTM(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
      "   ^~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:40: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_ASSERTM(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
      "                             ~~~~~~~~~~~^~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:230:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
      "                                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:250:34: note: in expansion of macro C10_UNLIKELY\n",
      " #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
      "                                  ^~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:302:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:588:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n",
      "     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
      "                                ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:3: note: in expansion of macro AT_ASSERTM\n",
      "   AT_ASSERTM(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
      "   ^~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:40: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_ASSERTM(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
      "                             ~~~~~~~~~~~^~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:230:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
      "                                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:250:34: note: in expansion of macro C10_UNLIKELY\n",
      " #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
      "                                  ^~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:302:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:588:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n",
      "     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
      "                                ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:3: note: in expansion of macro AT_ASSERTM\n",
      "   AT_ASSERTM(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
      "   ^~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:29:47: warning: T* at::Tensor::data() const [with T = unsigned char] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "   auto suppressed = suppressed_t.data<uint8_t>();\n",
      "                     ~~~~~~~~~~~~~~~~~~~~~~~~~~^~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:30:37: warning: T* at::Tensor::data() const [with T = long int] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "   auto order = order_t.data<int64_t>();\n",
      "                ~~~~~~~~~~~~~~~~~~~~~^~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:31:8: warning: T* at::Tensor::data() const [with T = float] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "   auto x1 = x1_t.data<scalar_t>();\n",
      "        ^~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:32:8: warning: T* at::Tensor::data() const [with T = float] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "   auto y1 = y1_t.data<scalar_t>();\n",
      "        ^~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:33:8: warning: T* at::Tensor::data() const [with T = float] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "   auto x2 = x2_t.data<scalar_t>();\n",
      "        ^~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:34:8: warning: T* at::Tensor::data() const [with T = float] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "   auto y2 = y2_t.data<scalar_t>();\n",
      "        ^~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:35:8: warning: T* at::Tensor::data() const [with T = float] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "   auto areas = areas_t.data<scalar_t>();\n",
      "        ^~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "[6/6] c++ -MMD -MF /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/vision.o.d -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DWITH_CUDA -I/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/vision.cpp -o /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/vision.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "cc1plus: warning: command line option -Wstrict-prototypes is valid for C/ObjC but not for C++\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Parallel.h:140,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:13,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/nms.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/vision.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/ParallelOpenMP.h:87: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
      " #pragma omp parallel for if ((end - begin) >= grain_size)\n",
      " \n",
      "In file included from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/vision.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/nms.h: In function at::Tensor nms(const at::Tensor&, const at::Tensor&, float):\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/nms.h:14:17: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   if (dets.type().is_cuda()) {\n",
      "                 ^\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/nms.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/vision.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/vision.cpp:3:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/ROIAlign.h: In function at::Tensor ROIAlign_forward(const at::Tensor&, const at::Tensor&, float, int, int, int):\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/ROIAlign.h:17:18: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   if (input.type().is_cuda()) {\n",
      "                  ^\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/nms.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/vision.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/vision.cpp:3:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/ROIAlign.h: In function at::Tensor ROIAlign_backward(const at::Tensor&, const at::Tensor&, float, int, int, int, int, int, int, int):\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/ROIAlign.h:37:17: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   if (grad.type().is_cuda()) {\n",
      "                 ^\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/nms.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/vision.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/vision.cpp:4:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/ROIPool.h: In function std::tuple<at::Tensor, at::Tensor> ROIPool_forward(const at::Tensor&, const at::Tensor&, float, int, int):\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/ROIPool.h:16:18: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   if (input.type().is_cuda()) {\n",
      "                  ^\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/nms.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/vision.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/vision.cpp:4:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/ROIPool.h: In function at::Tensor ROIPool_backward(const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, float, int, int, int, int, int, int):\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/ROIPool.h:37:17: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   if (grad.type().is_cuda()) {\n",
      "                 ^\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/nms.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/vision.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "g++ -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/vision.o /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.o /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.o /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/nms.o /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/ROIPool_cuda.o /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/ROIAlign_cuda.o -L/opt/conda/lib/python3.7/site-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.7/maskrcnn_benchmark/_C.cpython-37m-x86_64-linux-gnu.so\n",
      "running develop\n",
      "/opt/conda/lib/python3.7/site-packages/setuptools/command/easy_install.py:159: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
      "  EasyInstallDeprecationWarning,\n",
      "/opt/conda/lib/python3.7/site-packages/setuptools/command/install.py:37: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  setuptools.SetuptoolsDeprecationWarning,\n",
      "running egg_info\n",
      "creating maskrcnn_benchmark.egg-info\n",
      "writing maskrcnn_benchmark.egg-info/PKG-INFO\n",
      "writing dependency_links to maskrcnn_benchmark.egg-info/dependency_links.txt\n",
      "writing top-level names to maskrcnn_benchmark.egg-info/top_level.txt\n",
      "writing manifest file 'maskrcnn_benchmark.egg-info/SOURCES.txt'\n",
      "reading manifest file 'maskrcnn_benchmark.egg-info/SOURCES.txt'\n",
      "adding license file 'LICENSE'\n",
      "writing manifest file 'maskrcnn_benchmark.egg-info/SOURCES.txt'\n",
      "running build_ext\n",
      "building 'maskrcnn_benchmark._C' extension\n",
      "Emitting ninja build file /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/build.ninja...\n",
      "Compiling objects...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "[1/6] /usr/local/cuda/bin/nvcc  -DWITH_CUDA -I/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/ROIAlign_cuda.cu -o /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/ROIAlign_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "[2/6] /usr/local/cuda/bin/nvcc  -DWITH_CUDA -I/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/ROIPool_cuda.cu -o /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/ROIPool_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "[3/6] /usr/local/cuda/bin/nvcc  -DWITH_CUDA -I/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/nms.cu -o /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/nms.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "[4/6] c++ -MMD -MF /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.o.d -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DWITH_CUDA -I/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp -o /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "cc1plus: warning: command line option -Wstrict-prototypes is valid for C/ObjC but not for C++\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Parallel.h:140,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:13,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/ParallelOpenMP.h:87: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
      " #pragma omp parallel for if ((end - begin) >= grain_size)\n",
      " \n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:13,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp: In lambda function:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:71:40: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_DISPATCH_FLOATING_TYPES(dets.type(), \"nms\", [&] {\n",
      "                                        ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:207:28: note: in definition of macro AT_DISPATCH_FLOATING_TYPES\n",
      "     const auto& the_type = TYPE;                                            \\\n",
      "                            ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:13,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:209:56: warning: c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&) is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
      "     at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n",
      "                                                        ^\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:71:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES\n",
      "   AT_DISPATCH_FLOATING_TYPES(dets.type(), \"nms\", [&] {\n",
      "   ^~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:121:23: note: declared here\n",
      " inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
      "                       ^~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:209:56: warning: c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&) is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
      "     at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n",
      "                                                        ^\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:71:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES\n",
      "   AT_DISPATCH_FLOATING_TYPES(dets.type(), \"nms\", [&] {\n",
      "   ^~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:121:23: note: declared here\n",
      " inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
      "                       ^~~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp: In instantiation of at::Tensor nms_cpu_kernel(const at::Tensor&, const at::Tensor&, float) [with scalar_t = double]:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:71:3:   required from here\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:9:24: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_ASSERTM(!dets.type().is_cuda(), \"dets must be a CPU tensor\");\n",
      "               ~~~~~~~~~^~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:230:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
      "                                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:250:34: note: in expansion of macro C10_UNLIKELY\n",
      " #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
      "                                  ^~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:302:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:588:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n",
      "     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
      "                                ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:9:3: note: in expansion of macro AT_ASSERTM\n",
      "   AT_ASSERTM(!dets.type().is_cuda(), \"dets must be a CPU tensor\");\n",
      "   ^~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:9:24: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_ASSERTM(!dets.type().is_cuda(), \"dets must be a CPU tensor\");\n",
      "               ~~~~~~~~~^~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:230:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
      "                                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:250:34: note: in expansion of macro C10_UNLIKELY\n",
      " #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
      "                                  ^~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:302:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:588:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n",
      "     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
      "                                ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:9:3: note: in expansion of macro AT_ASSERTM\n",
      "   AT_ASSERTM(!dets.type().is_cuda(), \"dets must be a CPU tensor\");\n",
      "   ^~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:10:26: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_ASSERTM(!scores.type().is_cuda(), \"scores must be a CPU tensor\");\n",
      "               ~~~~~~~~~~~^~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:230:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
      "                                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:250:34: note: in expansion of macro C10_UNLIKELY\n",
      " #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
      "                                  ^~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:302:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:588:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n",
      "     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
      "                                ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:10:3: note: in expansion of macro AT_ASSERTM\n",
      "   AT_ASSERTM(!scores.type().is_cuda(), \"scores must be a CPU tensor\");\n",
      "   ^~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:10:26: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_ASSERTM(!scores.type().is_cuda(), \"scores must be a CPU tensor\");\n",
      "               ~~~~~~~~~~~^~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:230:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
      "                                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:250:34: note: in expansion of macro C10_UNLIKELY\n",
      " #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
      "                                  ^~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:302:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:588:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n",
      "     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
      "                                ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:10:3: note: in expansion of macro AT_ASSERTM\n",
      "   AT_ASSERTM(!scores.type().is_cuda(), \"scores must be a CPU tensor\");\n",
      "   ^~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:23: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_ASSERTM(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
      "              ~~~~~~~~~^~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:230:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
      "                                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:250:34: note: in expansion of macro C10_UNLIKELY\n",
      " #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
      "                                  ^~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:302:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:588:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n",
      "     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
      "                                ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:3: note: in expansion of macro AT_ASSERTM\n",
      "   AT_ASSERTM(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
      "   ^~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:23: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_ASSERTM(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
      "              ~~~~~~~~~^~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:230:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
      "                                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:250:34: note: in expansion of macro C10_UNLIKELY\n",
      " #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
      "                                  ^~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:302:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:588:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n",
      "     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
      "                                ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:3: note: in expansion of macro AT_ASSERTM\n",
      "   AT_ASSERTM(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
      "   ^~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:40: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_ASSERTM(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
      "                             ~~~~~~~~~~~^~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:230:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
      "                                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:250:34: note: in expansion of macro C10_UNLIKELY\n",
      " #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
      "                                  ^~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:302:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:588:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n",
      "     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
      "                                ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:3: note: in expansion of macro AT_ASSERTM\n",
      "   AT_ASSERTM(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
      "   ^~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:40: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_ASSERTM(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
      "                             ~~~~~~~~~~~^~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:230:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
      "                                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:250:34: note: in expansion of macro C10_UNLIKELY\n",
      " #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
      "                                  ^~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:302:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:588:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n",
      "     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
      "                                ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:3: note: in expansion of macro AT_ASSERTM\n",
      "   AT_ASSERTM(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
      "   ^~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:29:47: warning: T* at::Tensor::data() const [with T = unsigned char] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "   auto suppressed = suppressed_t.data<uint8_t>();\n",
      "                     ~~~~~~~~~~~~~~~~~~~~~~~~~~^~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:30:37: warning: T* at::Tensor::data() const [with T = long int] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "   auto order = order_t.data<int64_t>();\n",
      "                ~~~~~~~~~~~~~~~~~~~~~^~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:31:8: warning: T* at::Tensor::data() const [with T = double] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "   auto x1 = x1_t.data<scalar_t>();\n",
      "        ^~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:32:8: warning: T* at::Tensor::data() const [with T = double] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "   auto y1 = y1_t.data<scalar_t>();\n",
      "        ^~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:33:8: warning: T* at::Tensor::data() const [with T = double] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "   auto x2 = x2_t.data<scalar_t>();\n",
      "        ^~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:34:8: warning: T* at::Tensor::data() const [with T = double] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "   auto y2 = y2_t.data<scalar_t>();\n",
      "        ^~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:35:8: warning: T* at::Tensor::data() const [with T = double] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "   auto areas = areas_t.data<scalar_t>();\n",
      "        ^~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp: In instantiation of at::Tensor nms_cpu_kernel(const at::Tensor&, const at::Tensor&, float) [with scalar_t = float]:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:71:3:   required from here\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:9:24: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_ASSERTM(!dets.type().is_cuda(), \"dets must be a CPU tensor\");\n",
      "               ~~~~~~~~~^~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:230:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
      "                                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:250:34: note: in expansion of macro C10_UNLIKELY\n",
      " #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
      "                                  ^~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:302:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:588:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n",
      "     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
      "                                ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:9:3: note: in expansion of macro AT_ASSERTM\n",
      "   AT_ASSERTM(!dets.type().is_cuda(), \"dets must be a CPU tensor\");\n",
      "   ^~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:9:24: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_ASSERTM(!dets.type().is_cuda(), \"dets must be a CPU tensor\");\n",
      "               ~~~~~~~~~^~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:230:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
      "                                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:250:34: note: in expansion of macro C10_UNLIKELY\n",
      " #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
      "                                  ^~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:302:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:588:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n",
      "     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
      "                                ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:9:3: note: in expansion of macro AT_ASSERTM\n",
      "   AT_ASSERTM(!dets.type().is_cuda(), \"dets must be a CPU tensor\");\n",
      "   ^~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:10:26: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_ASSERTM(!scores.type().is_cuda(), \"scores must be a CPU tensor\");\n",
      "               ~~~~~~~~~~~^~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:230:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
      "                                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:250:34: note: in expansion of macro C10_UNLIKELY\n",
      " #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
      "                                  ^~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:302:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:588:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n",
      "     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
      "                                ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:10:3: note: in expansion of macro AT_ASSERTM\n",
      "   AT_ASSERTM(!scores.type().is_cuda(), \"scores must be a CPU tensor\");\n",
      "   ^~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:10:26: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_ASSERTM(!scores.type().is_cuda(), \"scores must be a CPU tensor\");\n",
      "               ~~~~~~~~~~~^~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:230:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
      "                                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:250:34: note: in expansion of macro C10_UNLIKELY\n",
      " #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
      "                                  ^~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:302:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:588:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n",
      "     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
      "                                ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:10:3: note: in expansion of macro AT_ASSERTM\n",
      "   AT_ASSERTM(!scores.type().is_cuda(), \"scores must be a CPU tensor\");\n",
      "   ^~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:23: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_ASSERTM(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
      "              ~~~~~~~~~^~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:230:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
      "                                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:250:34: note: in expansion of macro C10_UNLIKELY\n",
      " #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
      "                                  ^~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:302:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:588:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n",
      "     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
      "                                ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:3: note: in expansion of macro AT_ASSERTM\n",
      "   AT_ASSERTM(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
      "   ^~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:23: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_ASSERTM(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
      "              ~~~~~~~~~^~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:230:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
      "                                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:250:34: note: in expansion of macro C10_UNLIKELY\n",
      " #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
      "                                  ^~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:302:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:588:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n",
      "     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
      "                                ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:3: note: in expansion of macro AT_ASSERTM\n",
      "   AT_ASSERTM(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
      "   ^~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:40: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_ASSERTM(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
      "                             ~~~~~~~~~~~^~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:230:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
      "                                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:250:34: note: in expansion of macro C10_UNLIKELY\n",
      " #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
      "                                  ^~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:302:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:588:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n",
      "     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
      "                                ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:3: note: in expansion of macro AT_ASSERTM\n",
      "   AT_ASSERTM(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
      "   ^~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:40: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_ASSERTM(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
      "                             ~~~~~~~~~~~^~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:230:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
      "                                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:250:34: note: in expansion of macro C10_UNLIKELY\n",
      " #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
      "                                  ^~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:302:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:588:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n",
      "     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
      "                                ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:3: note: in expansion of macro AT_ASSERTM\n",
      "   AT_ASSERTM(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
      "   ^~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:29:47: warning: T* at::Tensor::data() const [with T = unsigned char] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "   auto suppressed = suppressed_t.data<uint8_t>();\n",
      "                     ~~~~~~~~~~~~~~~~~~~~~~~~~~^~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:30:37: warning: T* at::Tensor::data() const [with T = long int] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "   auto order = order_t.data<int64_t>();\n",
      "                ~~~~~~~~~~~~~~~~~~~~~^~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:31:8: warning: T* at::Tensor::data() const [with T = float] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "   auto x1 = x1_t.data<scalar_t>();\n",
      "        ^~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:32:8: warning: T* at::Tensor::data() const [with T = float] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "   auto y1 = y1_t.data<scalar_t>();\n",
      "        ^~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:33:8: warning: T* at::Tensor::data() const [with T = float] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "   auto x2 = x2_t.data<scalar_t>();\n",
      "        ^~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:34:8: warning: T* at::Tensor::data() const [with T = float] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "   auto y2 = y2_t.data<scalar_t>();\n",
      "        ^~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:35:8: warning: T* at::Tensor::data() const [with T = float] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "   auto areas = areas_t.data<scalar_t>();\n",
      "        ^~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "[5/6] c++ -MMD -MF /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.o.d -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DWITH_CUDA -I/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp -o /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "cc1plus: warning: command line option -Wstrict-prototypes is valid for C/ObjC but not for C++\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Parallel.h:140,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:13,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/ParallelOpenMP.h:87: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
      " #pragma omp parallel for if ((end - begin) >= grain_size)\n",
      " \n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp: In function at::Tensor ROIAlign_forward_cpu(const at::Tensor&, const at::Tensor&, float, int, int, int):\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:227:26: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_ASSERTM(!input.type().is_cuda(), \"input must be a CPU tensor\");\n",
      "                          ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:230:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
      "                                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:250:34: note: in expansion of macro C10_UNLIKELY\n",
      " #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
      "                                  ^~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:302:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:588:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n",
      "     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
      "                                ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:227:3: note: in expansion of macro AT_ASSERTM\n",
      "   AT_ASSERTM(!input.type().is_cuda(), \"input must be a CPU tensor\");\n",
      "   ^~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Device.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:7,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:228:25: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_ASSERTM(!rois.type().is_cuda(), \"rois must be a CPU tensor\");\n",
      "                         ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:230:39: note: in definition of macro C10_EXPAND_MSVC_WORKAROUND\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
      "                                       ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:250:34: note: in expansion of macro C10_UNLIKELY\n",
      " #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
      "                                  ^~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:302:7: note: in expansion of macro C10_UNLIKELY_OR_CONST\n",
      "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                         \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/c10/util/Exception.h:588:32: note: in expansion of macro TORCH_INTERNAL_ASSERT\n",
      "     C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
      "                                ^~~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:228:3: note: in expansion of macro AT_ASSERTM\n",
      "   AT_ASSERTM(!rois.type().is_cuda(), \"rois must be a CPU tensor\");\n",
      "   ^~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:13,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp: In lambda function:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:242:41: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   AT_DISPATCH_FLOATING_TYPES(input.type(), \"ROIAlign_forward\", [&] {\n",
      "                                         ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:207:28: note: in definition of macro AT_DISPATCH_FLOATING_TYPES\n",
      "     const auto& the_type = TYPE;                                            \\\n",
      "                            ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:13,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:209:56: warning: c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&) is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
      "     at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n",
      "                                                        ^\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:242:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES\n",
      "   AT_DISPATCH_FLOATING_TYPES(input.type(), \"ROIAlign_forward\", [&] {\n",
      "   ^~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:121:23: note: declared here\n",
      " inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
      "                       ^~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:209:56: warning: c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&) is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
      "     at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n",
      "                                                        ^\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:242:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES\n",
      "   AT_DISPATCH_FLOATING_TYPES(input.type(), \"ROIAlign_forward\", [&] {\n",
      "   ^~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:121:23: note: declared here\n",
      " inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
      "                       ^~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp: In lambda function:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:245:31: warning: T* at::Tensor::data() const [with T = double] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "          input.data<scalar_t>(),\n",
      "                               ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
      "     return __VA_ARGS__();                                                        \\\n",
      "            ^~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:212:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n",
      "       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)     \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:242:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES\n",
      "   AT_DISPATCH_FLOATING_TYPES(input.type(), \"ROIAlign_forward\", [&] {\n",
      "   ^~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:13,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:253:30: warning: T* at::Tensor::data() const [with T = double] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "          rois.data<scalar_t>(),\n",
      "                              ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
      "     return __VA_ARGS__();                                                        \\\n",
      "            ^~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:212:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n",
      "       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)     \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:242:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES\n",
      "   AT_DISPATCH_FLOATING_TYPES(input.type(), \"ROIAlign_forward\", [&] {\n",
      "   ^~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:13,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:254:32: warning: T* at::Tensor::data() const [with T = double] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "          output.data<scalar_t>());\n",
      "                                ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
      "     return __VA_ARGS__();                                                        \\\n",
      "            ^~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:212:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n",
      "       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)     \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:242:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES\n",
      "   AT_DISPATCH_FLOATING_TYPES(input.type(), \"ROIAlign_forward\", [&] {\n",
      "   ^~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:13,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp: In lambda function:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:245:31: warning: T* at::Tensor::data() const [with T = float] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "          input.data<scalar_t>(),\n",
      "                               ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
      "     return __VA_ARGS__();                                                        \\\n",
      "            ^~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:213:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n",
      "       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)       \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:242:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES\n",
      "   AT_DISPATCH_FLOATING_TYPES(input.type(), \"ROIAlign_forward\", [&] {\n",
      "   ^~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:13,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:253:30: warning: T* at::Tensor::data() const [with T = float] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "          rois.data<scalar_t>(),\n",
      "                              ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
      "     return __VA_ARGS__();                                                        \\\n",
      "            ^~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:213:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n",
      "       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)       \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:242:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES\n",
      "   AT_DISPATCH_FLOATING_TYPES(input.type(), \"ROIAlign_forward\", [&] {\n",
      "   ^~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:13,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:254:32: warning: T* at::Tensor::data() const [with T = float] is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n",
      "          output.data<scalar_t>());\n",
      "                                ^\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:66:12: note: in definition of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
      "     return __VA_ARGS__();                                                        \\\n",
      "            ^~~~~~~~~~~\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Dispatch.h:213:7: note: in expansion of macro AT_PRIVATE_CASE_TYPE\n",
      "       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)       \\\n",
      "       ^~~~~~~~~~~~~~~~~~~~\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:242:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES\n",
      "   AT_DISPATCH_FLOATING_TYPES(input.type(), \"ROIAlign_forward\", [&] {\n",
      "   ^~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:501:7: note: declared here\n",
      "   T * data() const {\n",
      "       ^~~~\n",
      "[6/6] c++ -MMD -MF /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/vision.o.d -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DWITH_CUDA -I/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/vision.cpp -o /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/vision.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "cc1plus: warning: command line option -Wstrict-prototypes is valid for C/ObjC but not for C++\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Parallel.h:140,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:13,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/nms.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/vision.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/ParallelOpenMP.h:87: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
      " #pragma omp parallel for if ((end - begin) >= grain_size)\n",
      " \n",
      "In file included from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/vision.cpp:2:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/nms.h: In function at::Tensor nms(const at::Tensor&, const at::Tensor&, float):\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/nms.h:14:17: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   if (dets.type().is_cuda()) {\n",
      "                 ^\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/nms.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/vision.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/vision.cpp:3:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/ROIAlign.h: In function at::Tensor ROIAlign_forward(const at::Tensor&, const at::Tensor&, float, int, int, int):\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/ROIAlign.h:17:18: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   if (input.type().is_cuda()) {\n",
      "                  ^\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/nms.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/vision.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/vision.cpp:3:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/ROIAlign.h: In function at::Tensor ROIAlign_backward(const at::Tensor&, const at::Tensor&, float, int, int, int, int, int, int, int):\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/ROIAlign.h:37:17: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   if (grad.type().is_cuda()) {\n",
      "                 ^\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/nms.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/vision.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/vision.cpp:4:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/ROIPool.h: In function std::tuple<at::Tensor, at::Tensor> ROIPool_forward(const at::Tensor&, const at::Tensor&, float, int, int):\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/ROIPool.h:16:18: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   if (input.type().is_cuda()) {\n",
      "                  ^\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/nms.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/vision.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "In file included from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/vision.cpp:4:\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/ROIPool.h: In function at::Tensor ROIPool_backward(const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, float, int, int, int, int, int, int):\n",
      "/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/ROIPool.h:37:17: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   if (grad.type().is_cuda()) {\n",
      "                 ^\n",
      "In file included from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
      "                 from /opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/nms.h:3,\n",
      "                 from /home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/vision.cpp:2:\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30: note: declared here\n",
      "   DeprecatedTypeProperties & type() const {\n",
      "                              ^~~~\n",
      "g++ -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/vision.o /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.o /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.o /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/nms.o /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/ROIPool_cuda.o /home/jupyter/vqa-maskrcnn-benchmark/build/temp.linux-x86_64-3.7/home/jupyter/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/ROIAlign_cuda.o -L/opt/conda/lib/python3.7/site-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.7/maskrcnn_benchmark/_C.cpython-37m-x86_64-linux-gnu.so\n",
      "copying build/lib.linux-x86_64-3.7/maskrcnn_benchmark/_C.cpython-37m-x86_64-linux-gnu.so -> maskrcnn_benchmark\n",
      "Creating /opt/conda/lib/python3.7/site-packages/maskrcnn-benchmark.egg-link (link to .)\n",
      "Adding maskrcnn-benchmark 0.1 to easy-install.pth file\n",
      "\n",
      "Installed /home/jupyter/vqa-maskrcnn-benchmark\n",
      "Processing dependencies for maskrcnn-benchmark==0.1\n",
      "Finished processing dependencies for maskrcnn-benchmark==0.1\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.join(home, \"vqa-maskrcnn-benchmark\"))\n",
    "!rm -rf build\n",
    "!python setup.py build develop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b694ab1d-7c1c-4c6e-8327-4d30f66995e2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-12-03 03:16:25--  https://dl.fbaipublicfiles.com/pythia/detectron_model/FAST_RCNN_MLP_DIM2048_FPN_DIM512.pkl\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1357496266 (1.3G) [application/octet-stream]\n",
      "Saving to: FAST_RCNN_MLP_DIM2048_FPN_DIM512.pkl\n",
      "\n",
      "FAST_RCNN_MLP_DIM20 100%[===================>]   1.26G  57.3MB/s    in 20s     \n",
      "\n",
      "2021-12-03 03:16:46 (63.2 MB/s) - FAST_RCNN_MLP_DIM2048_FPN_DIM512.pkl saved [1357496266/1357496266]\n",
      "\n",
      "--2021-12-03 03:16:46--  https://dl.fbaipublicfiles.com/pythia/detectron_model/e2e_faster_rcnn_X-101-64x4d-FPN_1x_MLP_2048_FPN_512.yaml\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1169 (1.1K) [text/plain]\n",
      "Saving to: e2e_faster_rcnn_X-101-64x4d-FPN_1x_MLP_2048_FPN_512.yaml\n",
      "\n",
      "e2e_faster_rcnn_X-1 100%[===================>]   1.14K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-12-03 03:16:46 (26.5 MB/s) - e2e_faster_rcnn_X-101-64x4d-FPN_1x_MLP_2048_FPN_512.yaml saved [1169/1169]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://dl.fbaipublicfiles.com/pythia/detectron_model/FAST_RCNN_MLP_DIM2048_FPN_DIM512.pkl\n",
    "!wget https://dl.fbaipublicfiles.com/pythia/detectron_model/e2e_faster_rcnn_X-101-64x4d-FPN_1x_MLP_2048_FPN_512.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a258449c-3c7c-4ed5-af2b-1009aa5a7708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.4.60-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.3 MB)\n",
      "     || 60.3 MB 99 kB/s             \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from opencv-python) (1.19.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.4.60\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "daeedd76-ddf7-4e16-9b86-f6ae3aa67acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (1.4.0+cu100)\n",
      "Collecting torch\n",
      "  Using cached torch-1.10.0-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (0.5.0+cu100)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.11.1-cp37-cp37m-manylinux1_x86_64.whl (23.3 MB)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch) (4.0.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.19.5)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision) (8.3.1)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.4.0+cu100\n",
      "    Uninstalling torch-1.4.0+cu100:\n",
      "      Successfully uninstalled torch-1.4.0+cu100\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.5.0+cu100\n",
      "    Uninstalling torchvision-0.5.0+cu100:\n",
      "      Successfully uninstalled torchvision-0.5.0+cu100\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 0.9.0 requires torch==1.9.0, but you have torch 1.10.0 which is incompatible.\n",
      "mmf 1.0.0rc12 requires torch<=1.9.0,>=1.6.0, but you have torch 1.10.0 which is incompatible.\n",
      "mmf 1.0.0rc12 requires torchvision<=0.10.0,>=0.7.0, but you have torchvision 0.11.1 which is incompatible.\u001b[0m\n",
      "Successfully installed torch-1.10.0 torchvision-0.11.1\n"
     ]
    }
   ],
   "source": [
    "# !pip3 install torch==1.4.0+cu100 torchvision==0.5.0+cu100 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip install --upgrade torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c874ee5d-1d37-4edc-8c0b-8c5f782542aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dc1c7bf-5383-4f25-9826-47c4971cc3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (1.9.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (0.11.1)\n",
      "Requirement already satisfied: torchaudio in /home/jupyter/.local/lib/python3.7/site-packages (0.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch) (4.0.0)\n",
      "Collecting torch\n",
      "  Using cached torch-1.10.0-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision) (8.3.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.19.5)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
      "     || 2.9 MB 8.0 MB/s            \n",
      "\u001b[?25hInstalling collected packages: torch, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.9.0\n",
      "    Uninstalling torch-1.9.0:\n",
      "      Successfully uninstalled torch-1.9.0\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 0.9.0\n",
      "    Uninstalling torchaudio-0.9.0:\n",
      "      Successfully uninstalled torchaudio-0.9.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mmf 1.0.0rc12 requires torch<=1.9.0,>=1.6.0, but you have torch 1.10.0 which is incompatible.\n",
      "mmf 1.0.0rc12 requires torchaudio<=0.9.0,>=0.6.0, but you have torchaudio 0.10.0 which is incompatible.\n",
      "mmf 1.0.0rc12 requires torchvision<=0.10.0,>=0.7.0, but you have torchvision 0.11.1 which is incompatible.\u001b[0m\n",
      "Successfully installed torch-1.10.0 torchaudio-0.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3efe950-0e70-4841-a36d-e50f3721f086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==1.8.0\n",
      "  Downloading torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5 MB)\n",
      "     |  | 683.5 MB 90.0 MB/s eta 0:00:01"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     || 735.5 MB 9.0 kB/s             \n",
      "\u001b[?25hCollecting torchvision==0.9.0\n",
      "  Downloading torchvision-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (17.3 MB)\n",
      "     || 17.3 MB 21.5 MB/s            \n",
      "\u001b[?25hCollecting torchaudio==0.8.0\n",
      "  Downloading torchaudio-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
      "     || 1.9 MB 66.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch==1.8.0) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.8.0) (4.0.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision==0.9.0) (8.3.1)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.9.0\n",
      "    Uninstalling torch-1.9.0:\n",
      "      Successfully uninstalled torch-1.9.0\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.10.0\n",
      "    Uninstalling torchvision-0.10.0:\n",
      "      Successfully uninstalled torchvision-0.10.0\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 0.9.0\n",
      "    Uninstalling torchaudio-0.9.0:\n",
      "      Successfully uninstalled torchaudio-0.9.0\n",
      "Successfully installed torch-1.8.0 torchaudio-0.8.0 torchvision-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch==1.8.0 torchvision==0.9.0 torchaudio==0.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8835488d-3b27-413a-9fcb-69c712ae55b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
      "Traceback (most recent call last):\n",
      "  File \"extract_features_vmb.py\", line 22, in <module>\n",
      "    from mmf.utils.download import download\n",
      "  File \"/home/jupyter/mmf/tools/scripts/features/mmf/__init__.py\", line 8, in <module>\n",
      "    from mmf import utils, common, modules, datasets, models\n",
      "  File \"/home/jupyter/mmf/tools/scripts/features/mmf/modules/__init__.py\", line 3, in <module>\n",
      "    import mmf.modules.metrics\n",
      "  File \"/home/jupyter/mmf/tools/scripts/features/mmf/modules/metrics.py\", line 53, in <module>\n",
      "    from mmf.datasets.processors.processors import EvalAIAnswerProcessor\n",
      "  File \"/home/jupyter/mmf/tools/scripts/features/mmf/datasets/__init__.py\", line 2, in <module>\n",
      "    from . import processors\n",
      "  File \"/home/jupyter/mmf/tools/scripts/features/mmf/datasets/processors/__init__.py\", line 5, in <module>\n",
      "    from mmf.datasets.processors.image_processors import TorchvisionTransforms\n",
      "  File \"/home/jupyter/mmf/tools/scripts/features/mmf/datasets/processors/image_processors.py\", line 9, in <module>\n",
      "    from torchvision import transforms\n",
      "ImportError: cannot import name 'transforms' from 'torchvision' (/home/jupyter/.cache/torch_extensions/py37_cpu/torchvision/torchvision.so)\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.join(home, \"mmf/tools/scripts/features/\"))#/\n",
    "out_folder = os.path.join(home, \"features/\")\n",
    "\n",
    "!python extract_features_vmb.py --config_file \"https://dl.fbaipublicfiles.com/pythia/detectron_model/detectron_model_x152.yaml\" \\\n",
    "                                --model_name \"X-152\" \\\n",
    "                                --output_folder $out_folder \\\n",
    "                                --image_dir \"/home/jupyter/.cache/torch/mmf/data/datasets/hateful_memes/defaults/images/img/\" \\\n",
    "                                --num_features 100 \\\n",
    "                                # --exclude_list \"/content/exclude.txt\" \\\n",
    "                                # --feature_name \"fc6\" \\\n",
    "                                # --confidence_threshold 0. \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b37787-a269-472b-ac5c-e15832a43e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-10.m86",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-10:m86"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
